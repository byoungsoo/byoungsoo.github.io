---
layout: post
title: "Kubernetes í´ëŸ¬ìŠ¤í„° êµ¬ì¶• [kubeadm]"
author: "Bys"
category: k8s
date: 2022-07-18 01:00:00
tags: kubernetes calico bgp kubeadm
---

# Kubernetes
ì´ë²ˆì—ëŠ” ê°œë³„ ì„œë²„ë“¤ì— kubeadmì„ ì´ìš©í•´ì„œ Kubernetes Master, Workerë¥¼ ì§ì ‘ êµ¬ì¶•í•´ë³´ë ¤ê³  í•œë‹¤. (í˜„ì¬ ì‹œì  kubernetes version 1.24)  
ìì„¸í•œ ë‚´ìš©ì€ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤. [Creating a cluster with kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)  

kubeadmì„ í†µí•´ êµ¬ì„±í•  ë•Œ í•„ìš”ì‚¬í•­ì€ ì•„ë˜ì™€ ê°™ë‹¤.  
- Need
  - A compatible Linux host. The Kubernetes project provides generic instructions for Linux distributions based on Debian and Red Hat, and those distributions without a package manager.
  - 2 GB or more of RAM per machine (any less will leave little room for your apps).
  - 2 CPUs or more
  - Full network connectivity between all machines in the cluster
  - Unique hostname, MAC address, and product_uuid for every node 
    ```bash
    #product_uuid
    sudo cat /sys/class/dmi/id/product_uuid
    ```
  - Certain ports are open on your machines.
    [Ports and Protocol](https://kubernetes.io/docs/reference/ports-and-protocols/)
  - Swap disabled. You MUST disable swap in order for the kubelet to work properly.

<br>

- Environment
  - AWS í™˜ê²½ì—ì„œ ì‘ì—…ì„ ì§„í–‰
  - Master: 2ëŒ€ (AmazonLinux, m5xlarge)
  - Worker: 2ëŒ€ (AmazonLinux, t3.medium)

<br>

- Objectives  
  - Install a single control-plane Kubernetes cluster
  - Install a Pod network on the cluster so that your Pods can talk to each other


## 1. Master ë…¸ë“œ, Worker ë…¸ë“œ í™˜ê²½ êµ¬ì„±

### 1.1 Master ë…¸ë“œ, Woker ë…¸ë“œ í™˜ê²½ êµ¬ì„±

`hostname set`  
í˜¸ìŠ¤íŠ¸ëª…ì€ ëª¨ë‘ Uniqueí•´ì•¼ í•˜ë©° dnsë“±ë¡ì´ í•„ìš”í•˜ë‹¤.(ì—¬ê¸°ì„œëŠ” hostsíŒŒì¼ì— ë“±ë¡)  
```bash
sudo hostnamectl set-hostname kube-master-node1
sudo hostnamectl set-hostname kube-master-node2
sudo hostnamectl set-hostname kube-worker-node1
sudo hostnamectl set-hostname kube-worker-node2
```

`swapoff`  
kubeletì€ swapë©”ëª¨ë¦¬ ì§€ì›ì„ í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ëª¨ë‘ offí•˜ëŠ” ê²ƒì„ ê³µì‹ì ìœ¼ë¡œ ê¶Œì¥í•˜ê³  ìˆë‹¤.  
```bash
sudo swapoff -a
cat /proc/meminfo | grep -i swap
##Print
SwapCached:            0 kB
SwapTotal:             0 kB
SwapFree:              0 kB
```

`security-group`  
awsí™˜ê²½ì´ë¯€ë¡œ ë…¸ë“œê°„ í†µì‹ ì„ ìœ„í•´ security-groupì„ ì„¤ì •í•´ì•¼ í•œë‹¤. 
ìš°ì„  sg-master-node, sg-worker-node ë‘ ê°œì˜ security groupì„ ìƒì„±í•˜ì—¬ ëª¨ë“  master ë…¸ë“œì—ëŠ” sg-master-node, worker ë…¸ë“œì—ëŠ” sg-worker-nodeë¥¼ ì ìš©í•œë‹¤.  

ê·¸ë¦¬ê³  ì•„ë˜ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•´ì„œ masterë…¸ë“œì™€ workerë…¸ë“œê°„ í•„ìš”í•œ í†µì‹ ê·¸ë£¹ì„ í—ˆìš©í•œë‹¤.  
[Ports and Protocol](https://kubernetes.io/docs/reference/ports-and-protocols/)


`kubeadm & kubelet & kubectl`  
ìƒì„¸ ì„¤ì¹˜ í˜ì´ì§€ëŠ” ì•„ë˜ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤.  
[Installing kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/)

- kubeadm, kubelet, kubectl ì„¤ì¹˜  

```bash
cat <<EOF | sudo tee /etc/yum.repos.d/kubernetes.repo
[kubernetes]
name=Kubernetes
baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-\$basearch
enabled=1
gpgcheck=1
gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

# Set SELinux in permissive mode (effectively disabling it)
sudo setenforce 0
sudo sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config

sudo yum install -y kubelet kubeadm kubectl --disableexcludes=kubernetes

sudo systemctl enable --now kubelet
```
<br>

`container runtime`  
íŒŒë“œì—ì„œ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ê¸° ìœ„í•´ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” Container Runtimeì„ ì‚¬ìš©í•œë‹¤. 
ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ì‚¬ìš©ìê°€ ì„ íƒí•œ Container Runtimeê³¼ì˜ ì¸í„°í˜ì´ìŠ¤ë¥¼ ìœ„í•´ ê¸°ë³¸ì ìœ¼ë¡œ CRI(Container Runtime Interface)ë¥¼ ì‚¬ìš©í•œë‹¤. 
Kubeadmì€ Container Runtimeì„ ì•Œë ¤ì§„ ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìë™ì ìœ¼ë¡œ ì°¾ì•„ ì„¤ì¹˜í•˜ì§€ë§Œ ë°œê²¬ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚¨ë‹¤.  

| Runtime                           | Path to Unix domain socket |
| :---                              | :--- |
| containerd                        | unix:///var/run/containerd/containerd.sock |
| CRI-O	                            | unix:///var/run/crio/crio.sock |
| Docker Engine (using cri-dockerd) | unix:///var/run/cri-dockerd.sock |

[![kubeadm_container001](/assets/it/k8s/k8s/kubeadm_container001.png){: width="55%" height="auto"}](/assets/it/k8s/k8s/kubeadm_container001.png)
[![kubeadm_container002](/assets/it/k8s/k8s/kubeadm_container002.png){: width="40%" height="auto"}](/assets/it/k8s/k8s/kubeadm_container002.png)

kubernetes 1.24 ë²„ì „ì—ì„œëŠ” docker ëŸ°íƒ€ì„ ì¤‘ë‹¨ì— ë”°ë¼ ê¸°ì¡´ dockerê°€ ì•„ë‹Œ CRIí”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œì¨ containerd, CRI-O ë“±ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.  
ì—¬ê¸°ì„œëŠ” CRIí”ŒëŸ¬ê·¸ì¸ìœ¼ë¡œ containerdë¥¼ ì‚¬ìš©í•œë‹¤. ë˜í•œ OCIì— runCë¥¼ ì‚¬ìš©í•œë‹¤.  

ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤. [Container Runtimes](https://kubernetes.io/docs/setup/production-environment/container-runtimes/#containerd)  
ì—¬ê¸°ì„œëŠ” containerdë¥¼ ì´ìš©í•œë‹¤. [Download containerd](https://github.com/containerd/containerd/blob/main/docs/getting-started.md)  
Release ë²„ì „ì€ ë¬¸ì„œì— í™•ì¸ ê°€ëŠ¥í•˜ë‹¤. [Release](https://github.com/containerd/containerd/releases)  


- container runtime ì„¤ì¹˜  
  ```bash
  wget https://github.com/containerd/containerd/releases/download/v1.6.24/containerd-1.6.24-linux-amd64.tar.gz
  tar Cxzvf /usr/local containerd-1.6.24-linux-amd64.tar.gz
  ```

- systemd ì„œë¹„ìŠ¤ ë“±ë¡  
  ```bash
  vim /usr/local/lib/systemd/system/containerd.service
  ```

  ```txt
  # Copyright The containerd Authors.
  #
  # Licensed under the Apache License, Version 2.0 (the "License");
  # you may not use this file except in compliance with the License.
  # You may obtain a copy of the License at
  #
  #     http://www.apache.org/licenses/LICENSE-2.0
  #
  # Unless required by applicable law or agreed to in writing, software
  # distributed under the License is distributed on an "AS IS" BASIS,
  # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  # See the License for the specific language governing permissions and
  # limitations under the License.

  [Unit]
  Description=containerd container runtime
  Documentation=https://containerd.io
  After=network.target local-fs.target

  [Service]
  #uncomment to fallback to legacy CRI plugin implementation with podsandbox support.
  #Environment="DISABLE_CRI_SANDBOXES=1"
  ExecStartPre=-/sbin/modprobe overlay
  ExecStart=/usr/local/bin/containerd

  Type=notify
  Delegate=yes
  KillMode=process
  Restart=always
  RestartSec=5
  # Having non-zero Limit*s causes performance problems due to accounting overhead
  # in the kernel. We recommend using cgroups to do container-local accounting.
  LimitNPROC=infinity
  LimitCORE=infinity
  LimitNOFILE=infinity
  # Comment TasksMax if your systemd version does not supports it.
  # Only systemd 226 and above support this version.
  TasksMax=infinity
  OOMScoreAdjust=-999

  [Install]
  WantedBy=multi-user.target
  ```

- systemd  
  ```bash
  systemctl daemon-reload
  systemctl enable --now containerd
  ```

- config.toml
  ì„¤ì¹˜ë¥¼ ì™„ë£Œí•œ í›„ ì„¤ì •íŒŒì¼ì„ ìƒì„±í•˜ê³  í•„ìš”í•œ ì„¤ì • ë“±ì„ ì¶”ê°€í•˜ê¸° ìœ„í•´ì„œëŠ” containerdì—ì„œ ì œê³µí•˜ëŠ” config ëª…ë ¹ì„ ì‚¬ìš©í•˜ì—¬ default config ì •ë³´ë¥¼ ìƒì„±í•œë‹¤.  
  ```bash
  mkdir -p /etc/containerd
  containerd config default > /etc/containerd/config.toml
  ```

  ìì„¸í•œ ë‚´ìš©ì€ ì•„ë˜ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤.  
  [containerd config](https://github.com/containerd/cri/blob/master/docs/config.md)



- runc
  ```
  wget https://github.com/opencontainers/runc/releases/download/v1.1.9/runc.amd64
  install -m 755 runc.amd64 /usr/local/sbin/runc
  ```

- CNI Plugin
  ```
  wget https://github.com/containernetworking/plugins/releases/download/v1.3.0/cni-plugins-linux-amd64-v1.3.0.tgz
  tar Cxzvf /opt/cni/bin cni-plugins-linux-amd64-v1.3.0.tgz
  ```

`container image(Optional)`  
ë§Œì•½ ë§ˆìŠ¤í„° ë…¸ë“œì— ì¸í„´í…Ÿì´ ë˜ì§€ ì•ŠëŠ”ë‹¤ë©´ ì•„ë˜ì˜ ë¬¸ì„œë¥¼ ì¶”ê°€ë¡œ ì°¸ê³ í•œë‹¤.  
[without an internet connection](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#without-internet-connection)

ì•„ë˜ì™€ ê°™ì´ í•„ìš”í•œ ì´ë¯¸ì§€ì™€ 
```bash
kubeadm config images list
kubeadm config images pull
```


ì—¬ê¸°ê¹Œì§€ ëª¨ë“  í™˜ê²½ êµ¬ì„±ì´ ëë‚˜ë©´ master, worker ê°ê° snapshotì„ ìƒì„±í•œë‹¤. ì¶”í›„ì— masterì™€ workerì˜ ìˆ˜ë¥¼ ëŠ˜ë¦¬ë©´ì„œ joinì— ì°¸ì—¬ì‹œì¼œ ìµœì¢…ì ìœ¼ë¡œëŠ” master, workerì˜ ìˆ˜ë¥¼ ì—¬ëŸ¬ê°œë¡œ ëŠ˜ë¦´ ì˜ˆì •ì´ë‹¤. 

<br>

### 1.2 Initializing Control-Plane Node  
ê³µì‹ ë¬¸ì„œë¥¼ ì½ì–´ë³´ë©´ ì•„ë˜ì™€ ê°™ì€ ê¸€ì´ ìˆë‹¤.  

> - (Recommended) If you have plans to upgrade this single control-plane kubeadm cluster to high availability you should specify the --control-plane-endpoint to set the shared endpoint for all control-plane nodes. Such an endpoint can be either a DNS name or an IP address of a load-balancer.  
    - ë§Œì•½ ê³ ê°€ìš©ì„± í™•ë³´ë¥¼ ìœ„í•œ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ë ¤ë©´ --control-plane-endpointë¥¼ ì„¤ì •í•´ì•¼ í•˜ë©° í•´ë‹¹ endpointëŠ” dnsì´ë¦„ì´ë‚˜ ë¡œë“œë°¸ëŸ°ì„œì˜ ipë¡œ endpointë¥¼ ì„¤ì •í•´ì•¼ í•œë‹¤. 
      ë”°ë¼ì„œ ì´ë²ˆì—ëŠ” NLBë¥¼ ìƒì„±í•˜ì—¬ NLBì˜ DNS Nameì„ endpointë¡œ ì„¤ì •í•´ë³´ë ¤ê³  í•œë‹¤. TG í¬íŠ¸ëŠ” API-Serverí¬íŠ¸ì¸ 6443ìœ¼ë¡œ í•˜ì˜€ê³  ë™ì¼í•˜ê²Œ Listenerì„¤ì •ë„ 6443í¬íŠ¸ë¡œ ë§ì·„ë‹¤.  

> - Choose a Pod network add-on, and verify whether it requires any arguments to be passed to kubeadm init. Depending on which third-party provider you choose, you might need to set the --pod-network-cidr to a provider-specific value. See Installing a Pod network add-on.
    - Pod networkì„ ìœ„í•œ add-onì„ ì„ íƒí•˜ëŠ” ë¶€ë¶„ì´ë©° í•„ìš”í•œ ê²½ìš° kubeadm init ì¸ìˆ˜ë¡œ ì „ë‹¬í•´ì£¼ì–´ì•¼ í•œë‹¤. --pod-network-cidr ì„ ì‚¬ìš©í•œë‹¤.  
    [CNI Add-on](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/#pod-network)  
    

> - (Optional) kubeadm tries to detect the container runtime by using a list of well known endpoints. To use different container runtime or if there are more than one installed on the provisioned node, specify the --cri-socket argument to kubeadm. See Installing a runtime.
    - ì•„ë˜ì™€ ê°™ì€ ë‚´ìš©ì´ ì¡´ì¬í•œë‹¤. CNIë¥¼ ì„¤ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ClusterDNS(CoreDNS)ëŠ” ì‹œì‘ í•˜ì§€ëª»í•  ê²ƒì´ë¼ëŠ”... ì¶”í›„ì— kubeadm init í›„ ë‹¤ì‹œ ì‚´í´ë³¸ë‹¤. ì—¬ê¸°ì„œë„ ì˜¤ë¥˜ê°€ ë°œìƒí•  ê²ƒì´ë‹¤. 
    Caution: This section contains important information about networking setup and deployment order. Read all of this advice carefully before proceeding. You must deploy a Container Network Interface (CNI) based Pod network add-on so that your Pods can communicate with each other. Cluster DNS (CoreDNS) will not start up before a network is installed.



> - (Optional) Unless otherwise specified, kubeadm uses the network interface associated with the default gateway to set the advertise address for this particular control-plane node's API server. To use a different network interface, specify the --apiserver-advertise-address=<ip-address> argument to kubeadm init. To deploy an IPv6 Kubernetes cluster using IPv6 addressing, you must specify an IPv6 address, for example --apiserver-advertise-address=fd00::101

kubeadm init ì„ í†µí•´ Control Plane ì„ êµ¬ì„±í•œë‹¤. --control-plane-endpointë¥¼ ì‚¬ìš©í•˜ì—¬ endpointë¥¼ ì œê³µí•˜ê¸° ë•Œë¬¸ì— --apiserver-advertise-address ì˜µì…˜ì€ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. 
ë§ˆìŠ¤í„° ì„œë²„ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•œë‹¤.  
```bash
kubeadm init \
--control-plane-endpoint "bys-dev-nlb-kubeadm-cluster-8fc7f1f5d5b6d0b6.elb.ap-northeast-2.amazonaws.com:6443" \
--upload-certs \
--pod-network-cidr "192.168.0.0/16" \
```

í•´ë‹¹ ì»¤ë§¨ë“œë¥¼ ì…ë ¥í•˜ì˜€ë”ë‹ˆ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤.  
```txt
kubeadm init \
> --control-plane-endpoint "bys-dev-nlb-kubeadm-cluster-8fc7f1f5d5b6d0b6.elb.ap-northeast-2.amazonaws.com:6443" \
> --upload-certs \
> --pod-network-cidr "192.168.0.0/16"

[init] Using Kubernetes version: v1.24.3
[preflight] Running pre-flight checks
	[WARNING FileExisting-tc]: tc not found in system path
	[WARNING Hostname]: hostname "kube-master-node1" could not be reached
	[WARNING Hostname]: hostname "kube-master-node1": lookup kube-master-node1 on 10.20.0.2:53: no such host
error execution phase preflight: [preflight] Some fatal errors occurred:
	[ERROR FileContent--proc-sys-net-bridge-bridge-nf-call-iptables]: /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
	[ERROR FileContent--proc-sys-net-ipv4-ip_forward]: /proc/sys/net/ipv4/ip_forward contents are not set to 1
[preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...`
To see the stack trace of this error execute with --v=5 or higher
```
1. WARNINGì´ì§€ë§Œ ë°˜ë“œì‹œ hostnameì„ DNSì— ë“±ë¡ì„ í•˜ì
    - ìš°ì„ ì€ /etc/hostsì— ì¶”ê°€ í•¨
      ```
      vim /etc/hosts
      10.20.1.232 kube-master-node1
      10.20.2.10 kube-master-node2 
      10.20.1.67 kube-worker-node1
      10.20.2.22 kube-worker-node2
      ```
2. /proc/sys/net/bridge/bridge-nf-call-iptables does not exist
    - ì •í™•í•œ ì›ì¸ì€ ì¶”ê°€ í™•ì¸ì´ í•„ìš”í•˜ë‹¤. ìš°ì„  ì•„ë˜ì™€ ê°™ì´ ì¡°ì¹˜ í›„ ë„˜ì–´ê°”ë‹¤. (ì•„ë˜ëŠ” í™•ì¸ ê²°ê³¼)  
      > ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ìš”êµ¬ ì‚¬í•­  
        ì¿ ë²„ë„¤í‹°ìŠ¤ë¥¼ ë¹Œë“œí•˜ê±°ë‚˜ ë°°í¬í•˜ëŠ” í”ŒëŸ¬ê·¸ì¸ ê°œë°œìì™€ ì‚¬ìš©ìë“¤ì„ ìœ„í•´, í”ŒëŸ¬ê·¸ì¸ì€ kube-proxyë¥¼ ì§€ì›í•˜ê¸° ìœ„í•œ íŠ¹ì • ì„¤ì •ì´ í•„ìš”í•  ìˆ˜ë„ ìˆë‹¤. iptables í”„ë¡ì‹œëŠ” iptablesì— ì˜ì¡´í•˜ë©°, í”ŒëŸ¬ê·¸ì¸ì€ ì»¨í…Œì´ë„ˆ íŠ¸ë˜í”½ì´ iptablesì— ì‚¬ìš© ê°€ëŠ¥í•˜ë„ë¡ í•´ì•¼ í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í”ŒëŸ¬ê·¸ì¸ì´ ì»¨í…Œì´ë„ˆë¥¼ ë¦¬ëˆ…ìŠ¤ ë¸Œë¦¿ì§€ì— ì—°ê²°í•˜ëŠ” ê²½ìš°, í”ŒëŸ¬ê·¸ì¸ì€ net/bridge/bridge-nf-call-iptables sysctlì„ 1 ë¡œ ì„¤ì •í•˜ì—¬ iptables í”„ë¡ì‹œê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•´ì•¼ í•œë‹¤. í”ŒëŸ¬ê·¸ì¸ì´ Linux ë¸Œë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ëŒ€ì‹  Open vSwitchë‚˜ ë‹¤ë¥¸ ë©”ì»¤ë‹ˆì¦˜ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš°, ì»¨í…Œì´ë„ˆ íŠ¸ë˜í”½ì´ í”„ë¡ì‹œì— ëŒ€í•´ ì ì ˆí•˜ê²Œ ë¼ìš°íŒ…ë˜ë„ë¡ í•´ì•¼ í•œë‹¤.
      ```bash
      modprobe br_netfilter
      echo 1 > /proc/sys/net/bridge/bridge-nf-call-iptables
      ```
3. /proc/sys/net/ipv4/ip_forward contents are not set to 1  
    - ë§ˆì°¬ê°€ì§€ë¡œ ì •í•™í™˜ ì›ì¸ì€ ì¶”ê°€ í™•ì¸ í•„ìš”í•˜ë‹¤. ì•„ë˜ì™€ ê°™ì´ ì¡°ì¹˜ í›„ ë„˜ì–´ê°”ë‹¤.  
      ```bash
      echo '1' > /proc/sys/net/ipv4/ip_forward
      ```
<br>

ì¡°ì¹˜ë¥¼ í•œ í›„ ë‹¤ì‹œ kubeadm init ì»¤ë§¨ë“œë¥¼ ìˆ˜í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ìµœì¢…ì ìœ¼ë¡œ Your Kubernetes control-plane has initialized successfully! ë©”ì„¸ì§€ë¥¼ ë³¼ ìˆ˜ ìˆë‹¤. 

```bash
# ......ìƒëµ
[bootstrap-token] Using token: 3qz1dn.ci5py76kh2jkuxad
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] Configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] Configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] Configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" names  pace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

Alternatively, if you are the root user, you can run:

  export KUBECONFIG=/etc/kubernetes/admin.conf

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/ã…‹

You can now join any number of the control-plane node running the following command on each as root:

  kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
	--discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34 \
	--control-plane --certificate-key 898832cb7763894e8f82e6f5930e043f43c50a5c5a0587ec28667a479ed8ae0d

Please note that the certificate-key gives access to cluster sensitive data, keep it secret!
As a safeguard, uploaded-certs will be deleted in two hours; If necessary, you can use
"kubeadm init phase upload-certs --upload-certs" to reload certs afterward.

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
	--discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34
```
<br>

ë©”ì„¸ì§€ ë§ˆì§€ë§‰ ì¦ˆìŒ kubeadm join ë©”ì„¸ì§€ëŠ” ë³µì‚¬í•˜ì—¬ Workerë…¸ë“œì—ì„œ ì‹¤í–‰í•´ ì£¼ë©´ í´ëŸ¬ìŠ¤í„°ì— ë…¸ë“œê°€ ì¡°ì¸ì´ ëœë‹¤. (1.4ì—ì„œ ë‹¤ì‹œ)  
ìœ„ ë©”ì„¸ì§€ ì¤‘ê°„ì— Master ë…¸ë“œì—ì„œëŠ” admin.confë¥¼ ~/.kube/config í•˜ìœ„ë¡œ ì¹´í”¼í•´ì£¼ë©´ kubectl ì»¤ë§¨ë“œê°€ ë™ì‘í•˜ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.  
```bash
kubectl get nodes
##Print
NAME                STATUS     ROLES           AGE     VERSION
kube-master-node1   NotReady   control-plane   7m39s   v1.24.3
```
```bash
kubectl get pods -A
##Print
NAMESPACE     NAME                                        READY   STATUS    RESTARTS   AGE
kube-system   coredns-6d4b75cb6d-bn4wg                    0/1     Pending   0          4m33s
kube-system   coredns-6d4b75cb6d-rtl2f                    0/1     Pending   0          4m33s
kube-system   etcd-kube-master-node1                      1/1     Running   2          4m46s
kube-system   kube-apiserver-kube-master-node1            1/1     Running   2          4m47s
kube-system   kube-controller-manager-kube-master-node1   1/1     Running   2          4m47s
kube-system   kube-proxy-ztlqf                            1/1     Running   0          4m33s
kube-system   kube-scheduler-kube-master-node1            1/1     Running   2          4m45s
```

ë™ì‘ í•˜ëŠ” ê²ƒì€ í™•ì¸í•˜ì˜€ê³  ì•„ì§ nodeì˜ ìƒíƒœê°€ NotReadyì´ë©° corednsíŒŒë“œê°€ pending ìƒíƒœì´ë¯€ë¡œ ìƒíƒœë¥¼ í™•ì¸í•´ë³´ì•˜ë‹¤.  
ìš°ì„  ë…¸ë“œì˜ ê²½ìš°ëŠ” ì•„ë˜ì™€ ê°™ì´ CNI í”ŒëŸ¬ê·¸ì¸ì´ ì´ˆê¸°í™” ë˜ì§€ ì•Šì€ í˜„ìƒì´ ìˆì—ˆë‹¤.  
```bash
kubectl describe node kube-master-node1
##Print
#.....ìƒëµ
Conditions:
  Type             Status  LastHeartbeatTime                 LastTransitionTime                Reason                       Message
  ----             ------  -----------------                 ------------------                ------                       -------
  MemoryPressure   False   Mon, 18 Jul 2022 07:39:37 +0000   Mon, 18 Jul 2022 07:29:07 +0000   KubeletHasSufficientMemory   kubelet has sufficient memory available
  DiskPressure     False   Mon, 18 Jul 2022 07:39:37 +0000   Mon, 18 Jul 2022 07:29:07 +0000   KubeletHasNoDiskPressure     kubelet has no disk pressure
  PIDPressure      False   Mon, 18 Jul 2022 07:39:37 +0000   Mon, 18 Jul 2022 07:29:07 +0000   KubeletHasSufficientPID      kubelet has sufficient PID available
  Ready            False   Mon, 18 Jul 2022 07:39:37 +0000   Mon, 18 Jul 2022 07:29:07 +0000   KubeletNotReady              container runtime network not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized
```

corednsì˜ ê²½ìš° Scheduling ì— ì‹¤íŒ¨í–ˆë‹¤. ë…¸ë“œê°€ not-readyìƒíƒœì—¬ì„œ ê°€ëŠ¥í•œ ë…¸ë“œê°€ ì—†ëŠ” ìƒíƒœì´ë¯€ë¡œ í•´ë‹¹ íŒŒë“œëŠ” ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤. 
ë¨¼ì € ë…¸ë“œë¥¼ ì •ìƒ ë³µêµ¬ ì‹œí‚¤ëŠ” ì¼ì„ ì§„í–‰í•´ì•¼í•œë‹¤.  
```bash
kubectl describe pod coredns-6d4b75cb6d-bn4wg -n kube-system
##Print
#.....ìƒëµ
Events:
  Type     Reason            Age                 From               Message
  ----     ------            ----                ----               -------
  Warning  FailedScheduling  2m6s (x3 over 12m)  default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node.kubernetes.io/not-ready: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
```
<br>

### 1.3 Calico CNI(Container Runtime Interface)  
ìœ„ ì—ì„œ ë°œìƒí•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ CNI Pluginì„ ì„¤ì¹˜í•´ì•¼ í•œë‹¤. CNIëŠ” ë‹¤ë¥¸ ë…¸ë“œë“¤ì— ìƒì„±ëœ Pod(Container)ê°„ í†µì‹ ì„ ìœ„í•œ Interface ë¼ê³  ìƒê°í•˜ë©´ ëœë‹¤. 

Flannel, Calico ë“± ë‹¤ì–‘í•œ ì¢…ë¥˜ì˜ CNIê°€ ì¡´ì¬í•˜ë©° ê·¸ ì¤‘ì—ì„œë„ ì´ ë²ˆì—ëŠ” ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ” Calicoë¥¼ ì„¤ì¹˜í•´ë³´ë ¤ê³  í•œë‹¤.  
ì‰½ê²Œ ì„¤ì¹˜ë¥¼ ì›í•œë‹¤ë©´ Flannelë¡œ ì„¤ì¹˜ë¥¼ í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤. Flannelì€ ì¿ ë²„ë„¤í‹°ìŠ¤ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•˜ëŠ” ë§¤ìš° ê°„ë‹¨í•œ overlay ë„¤íŠ¸ì›Œí¬ì´ë©° ë‹¤ë¥¸ í”ŒëŸ¬ê·¸ì¸ì— ë¹„í•´ì„œ ì„¤ì¹˜ ë° êµ¬ì„±ì´ ì‰¬ìš´ ê²ƒìœ¼ë¡œ í™•ì¸ëœë‹¤.  

`Calico`  
ìì„¸í•œ ì‚¬í•­ì€ ê³µì‹ ë¬¸ì„œë¥¼ í™•ì¸í•œë‹¤. [Calico Install](https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises#install-calico)  
Master ë…¸ë“œì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ ìˆ˜í–‰í•œë‹¤.  
```bash
curl -LO https://docs.tigera.io/calico/latest/manifests/calico.yaml
kubectl apply -f calico.yaml
```

ë°°í¬ë¥¼ ì§„í–‰í•˜ê³  ë‚˜ë©´ calicoê°€ ë°°í¬ëœ ê²ƒì„ ë³¼ ìˆ˜ ìˆê³  ì´ ì™€ í•¨ê»˜ corednsëŠ” Runningìœ¼ë¡œ ìƒíƒœ ê°’ì´ ë³€ê²½ ë˜ì—ˆë‹¤.  
ë…¸ë“œì˜ ìƒíƒœ ë˜í•œ Readyìƒíƒœë¡œ ë³€ê²½ë˜ì—ˆë‹¤.  
```bash
kubectl get nodes
##Print
NAME                STATUS   ROLES           AGE   VERSION
kube-master-node1   Ready    control-plane   53m   v1.24.3
```
```bash
kubectl get pods -A
##Print
NAMESPACE     NAME                                        READY   STATUS    RESTARTS   AGE
kube-system   calico-kube-controllers-6766647d54-gvsn6    0/1     Pending   0          37s
kube-system   calico-node-5kx97                           1/1     Running   0          37s
kube-system   coredns-6d4b75cb6d-bn4wg                    1/1     Running   0          41m
kube-system   coredns-6d4b75cb6d-rtl2f                    1/1     Running   0          41m
kube-system   etcd-kube-master-node1                      1/1     Running   2          41m
kube-system   kube-apiserver-kube-master-node1            1/1     Running   2          41m
kube-system   kube-controller-manager-kube-master-node1   1/1     Running   2          41m
kube-system   kube-proxy-ztlqf                            1/1     Running   0          41m
kube-system   kube-scheduler-kube-master-node1            1/1     Running   2          41m
```

ê·¸ëŸ°ë° ì—¬ê¸°ì„œ calico-kube-controllersê°€ pending ìƒíƒœì—ì„œ ì§„í–‰ë˜ì§€ ì•Šì•˜ë‹¤.  
í•´ë‹¹ ì´ìœ ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ì—ì„œ íŒŒë“œëŠ” ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì— ìŠ¤ì¼€ì¥´ë§ ë˜ì§€ ì•Šë„ë¡ ë³´ì•ˆìƒ ë˜ì–´ìˆê¸° ë•Œë¬¸ì´ë‹¤. 
```bash
kubecetl describe pod calico-kube-controllers-6766647d54-gvsn6 -n kube-system
##Print
#.....ìƒëµ
Conditions:
  Type           Status
  PodScheduled   False
Volumes:
  kube-api-access-khfdc:
    Type:                    Projected (a volume that contains injected data from multiple sources)
    TokenExpirationSeconds:  3607
    ConfigMapName:           kube-root-ca.crt
    ConfigMapOptional:       <nil>
    DownwardAPI:             true
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/master:NoSchedule
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age    From               Message
  ----     ------            ----   ----               -------
  Warning  FailedScheduling  3m14s  default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
```

ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ íŒŒë“œë¥¼ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì— ì˜¬ë¦´ ìˆ˜ ìˆë„ë¡ ì„¤ì •í•œë‹¤. (Worker ë…¸ë“œë¥¼ ë¨¼ì € ì¡°ì¸ì‹œì¼œë„ í•´ë‹¹ ë¬¸ì œ í•´ê²° ê°€ëŠ¥)  
ìì„¸í•œ ì‚¬í•­ì€ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤. [Control plane node isolation](https://17billion.github.io/kubernetes/2019/04/24/kubernetes_control_plane_working.html)  
```bash
kubectl taint nodes --all node-role.kubernetes.io/control-plane- node-role.kubernetes.io/master-
```

ì•„ë˜ì™€ ê°™ì´ ì •ìƒì ìœ¼ë¡œ calico-kube-controllers ê¹Œì§€ ë™ì‘ì´ ì™„ë£Œë˜ì—ˆë‹¤.  
```bash
kubectl describe pod calico-kube-controllers-6766647d54-gvsn6 -n kube-system
##Print
#.....ìƒëµ
QoS Class:                   BestEffort
Node-Selectors:              kubernetes.io/os=linux
Tolerations:                 CriticalAddonsOnly op=Exists
                             node-role.kubernetes.io/master:NoSchedule
                             node.kubernetes.io/not-ready:NoExecute op=Exists for 300s
                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s
Events:
  Type     Reason            Age   From               Message
  ----     ------            ----  ----               -------
  Warning  FailedScheduling  14m   default-scheduler  0/1 nodes are available: 1 node(s) had untolerated taint {node-role.kubernetes.io/control-plane: }. preemption: 0/1 nodes are available: 1 Preemption is not helpful for scheduling.
  Normal   Scheduled         10m   default-scheduler  Successfully assigned kube-system/calico-kube-controllers-6766647d54-gvsn6 to kube-master-node1
  Normal   Pulling           10m   kubelet            Pulling image "docker.io/calico/kube-controllers:v3.23.2"
  Normal   Pulled            10m   kubelet            Successfully pulled image "docker.io/calico/kube-controllers:v3.23.2" in 6.944828969s
  Normal   Created           10m   kubelet            Created container calico-kube-controllers
  Normal   Started           10m   kubelet            Started container calico-kube-controllers
```
```bash
kubectl get pods -A
##Print
NAMESPACE     NAME                                        READY   STATUS    RESTARTS   AGE
kube-system   calico-kube-controllers-6766647d54-gvsn6    1/1     Running   0          12m
kube-system   calico-node-5kx97                           1/1     Running   0          12m
kube-system   coredns-6d4b75cb6d-bn4wg                    1/1     Running   0          52m
kube-system   coredns-6d4b75cb6d-rtl2f                    1/1     Running   0          52m
kube-system   etcd-kube-master-node1                      1/1     Running   2          52m
kube-system   kube-apiserver-kube-master-node1            1/1     Running   2          52m
kube-system   kube-controller-manager-kube-master-node1   1/1     Running   2          52m
kube-system   kube-proxy-ztlqf                            1/1     Running   0          52m
kube-system   kube-scheduler-kube-master-node1            1/1     Running   2          52m
```
<br>

### 1.4 Workerë…¸ë“œ Join  
ë‹¤ì‹œ Clusterêµ¬ì„±ìœ¼ë¡œ ëŒì•„ì™€ì„œ kubeadm init í›„ join ì»¤ë§¨ë“œë¥¼ í™•ì¸í•œë‹¤. 

í•´ë‹¹ ì»¤ë§¨ë“œëŠ” master ë…¸ë“œê°€ ì¶”ê°€ ë  ë•Œ joinë˜ëŠ” ì»¤ë§¨ë“œì´ë‹¤.  
```bash
# You can now join any number of the control-plane node running the following command on each as root:
kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
	--discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34 \
	--control-plane --certificate-key 898832cb7763894e8f82e6f5930e043f43c50a5c5a0587ec28667a479ed8ae0d
```

í•´ë‹¹ ì»¤ë§¨ë“œëŠ” worker ë…¸ë“œê°€ ì¶”ê°€ ë  ë•Œ joinë˜ëŠ” ì»¤ë§¨ë“œì´ë‹¤.  
```bash
#Then you can join any number of worker nodes by running the following on each as root:
kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
	--discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34
```

ë¨¼ì € workerë…¸ë“œì—ì„œ rootë¡œ ìœ„ ì»¤ë§¨ë“œë¥¼ ìˆ˜í–‰í•´ë³¸ë‹¤.  
```bash
kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
  --discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34
##Print
[preflight] Running pre-flight checks
	[WARNING FileExisting-tc]: tc not found in system path
[preflight] Reading configuration from the cluster...
[preflight] FYI: You can look at this config file with 'kubectl -n kube-system get cm kubeadm-config -o yaml'
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Starting the kubelet
[kubelet-start] Waiting for the kubelet to perform the TLS Bootstrap...

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

Run 'kubectl get nodes' on the control-plane to see this node join the cluster.
```

ì•„ë˜ì™€ ê°™ì´ workerë…¸ë“œê°€ ì¶”ê°€ ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  
```bash
kubectl get nodes
##Print
NAME                STATUS   ROLES           AGE   VERSION
kube-master-node1   Ready    control-plane   67m   v1.24.3
kube-worker-node1   Ready    <none>          53s   v1.24.3
```

nodeì— ROLESê°€ noneìœ¼ë¡œ í‘œì‹œ ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. ì•„ë˜ì™€ ê°™ì´ ì»¤ë§¨ë“œë¥¼ í†µí•´ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.  
```bash
kubectl label node <node name> node-role.kubernetes.io/<role name>=<key-(any name)>
kubectl label node kube-worker-node1 node-role.kubernetes.io/worker=
kubectl label node kube-worker-node2 node-role.kubernetes.io/worker=
```
```bash
kubectl get nodes
##Print
NAME                STATUS   ROLES           AGE     VERSION
kube-master-node1   Ready    control-plane   18h     v1.24.3
kube-worker-node1   Ready    worker          16h     v1.24.3
kube-worker-node2   Ready    worker          6m46s   v1.24.3
```
<br>


### 1.5 Masterë…¸ë“œ Join  
ì‹œê°„ì´ ì§€ë‚˜ ë‹¤ì‹œ ìœ„ì—ì„œ ìµœì´ˆ kubeadm init í•˜ê³  ë‚˜ì˜¨ control-plane join ì»¤ë§¨ë“œë¥¼ í†µí•´ kube-master-node2 ë…¸ë“œë¥¼ ì¶”ê°€í•˜ë ¤ê³  í•˜ì˜€ì„ ë•Œ ì•„ë˜ì™€ ê°™ì€ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì˜€ë‹¤.  

```txt
[download-certs] Downloading the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace
error execution phase control-plane-prepare/download-certs: error downloading certs: error downloading the secret: Secret "kubeadm-certs" was not found in the "kube-system" Namespace. This Secret might have expired. Please, run `kubeadm init phase upload-certs --upload-certs` on a control plane to generate a new one
```


ìµœì´ˆ kubeadm init ë‹¹ì‹œ --upload-certs ì˜µì…˜ì„ í†µí•´ êµ¬ì„±ì„ í•˜ì˜€ì—ˆë‹¤. --upload-certs ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´ initì„ ì§„í–‰í•˜ë©´ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì˜ ì¸ì¦ì„œë¥¼ ì„ì‹œë¡œ í´ëŸ¬ì„œí„°ì˜ Secretì— ë³´ê´€í•  ìˆ˜ ìˆë‹¤. 
í•˜ì§€ë§Œ ì—…ë¡œë“œ ëœ Secretì€ 2ì‹œê°„ ì´ í›„ì—ëŠ” ë§Œë£Œê°€ ë˜ë¯€ë¡œ ì•„ë˜ì™€ ê°™ì´ ìƒˆë¡œìš´ ì¸ì¦ì„œë¥¼ ì—…ë¡œë“œ í•œë‹¤.  
ìì„¸í•œ ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•œë‹¤. [Uploading control-plane certificates to the cluster](https://kubernetes.io/docs/reference/setup-tools/kubeadm/kubeadm-init/#uploading-control-plane-certificates-to-the-cluster)  

```bash
kubeadm init phase upload-certs --upload-certs
##Print
[upload-certs] Storing the certificates in Secret "kubeadm-certs" in the "kube-system" Namespace
[upload-certs] Using certificate key:
8cbbfb6ddd28539f95e23343d9e085777e9a7adb4df084d6031116b3f5a836ef
```
ì´ë ‡ê²Œ í•˜ë©´ ìƒˆë¡œìš´ certificate keyê°€ ìƒì„±ëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.  

í•´ë‹¹ í‚¤ë¥¼ ë‹¤ì‹œ ì•„ë˜ì™€ ê°™ì´ --certificate-key ì˜µì…˜ìœ¼ë¡œ ë„£ì–´ì¤€ë‹¤. ê·¸ëŸ¬ë©´ ì•„ë˜ì™€ ê°™ì´ ì •ìƒì ìœ¼ë¡œ Joinëœ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.  
```bash
kubeadm join nlb-kube-master-a0dca3b259bf3238.elb.ap-northeast-2.amazonaws.com:6443 --token 3qz1dn.ci5py76kh2jkuxad \
	--discovery-token-ca-cert-hash sha256:b43b7bfb924b8b08d915a4db98a286be911c6bd46849c0d2022f58ec5b834d34 \
	--control-plane --certificate-key 8cbbfb6ddd28539f95e23343d9e085777e9a7adb4df084d6031116b3f5a836ef

##Print
This node has joined the cluster and a new control plane instance was created:

* Certificate signing request was sent to apiserver and approval was received.
* The Kubelet was informed of the new secure connection details.
* Control plane label and taint were applied to the new node.
* The Kubernetes control plane instances scaled up.
* A new etcd member was added to the local/stacked etcd cluster.

To start administering your cluster from this node, you need to run the following as a regular user:

	mkdir -p $HOME/.kube
	sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
	sudo chown $(id -u):$(id -g) $HOME/.kube/config

Run 'kubectl get nodes' to see this node join the cluster.
```

ìµœì¢…ì ìœ¼ë¡œ ë§ˆìŠ¤í„°ë…¸ë“œ 2ëŒ€ì™€ ì›Œì»¤ë…¸ë“œ 2ëŒ€ì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ì˜€ë‹¤.  
```bash
kubectl get nodes
##Print
NAME                STATUS   ROLES           AGE     VERSION
kube-master-node1   Ready    control-plane   19h     v1.24.3
kube-master-node2   Ready    control-plane   5m37s   v1.24.3
kube-worker-node1   Ready    worker          18h     v1.24.3
kube-worker-node2   Ready    worker          69m     v1.24.3
```



## 2. TroubleShooting

### 2.1 Calico Ready  
ìƒˆë¡œìš´ master, worker ë…¸ë“œë“¤ì´ ì¶”ê°€ ëœ ì´ í›„ ë¶€í„° calico-node íŒŒë“œë“¤ì´ ëª¨ë“œ Readyì— ì‹¤íŒ¨í–ˆë‹¤.  
```bash
kubectl get pods -A
##Print
NAMESPACE     NAME                                        READY   STATUS    RESTARTS        AGE
kube-system   calico-kube-controllers-6766647d54-gvsn6    1/1     Running   0               18h
kube-system   calico-node-5kx97                           0/1     Running   0               18h
kube-system   calico-node-h6qm4                           0/1     Running   0               18h
kube-system   calico-node-n9p9r                           0/1     Running   0               71m
kube-system   calico-node-sjmk7                           0/1     Running   0               7m51s
kube-system   coredns-6d4b75cb6d-bn4wg                    1/1     Running   0               19h
kube-system   coredns-6d4b75cb6d-rtl2f                    1/1     Running   0               19h
kube-system   etcd-kube-master-node1                      1/1     Running   2               19h
kube-system   etcd-kube-master-node2                      1/1     Running   0               7m46s
kube-system   kube-apiserver-kube-master-node1            1/1     Running   2               19h
kube-system   kube-apiserver-kube-master-node2            1/1     Running   0               7m50s
kube-system   kube-controller-manager-kube-master-node1   1/1     Running   3 (7m35s ago)   19h
kube-system   kube-controller-manager-kube-master-node2   1/1     Running   0               7m50s
kube-system   kube-proxy-dm4p8                            1/1     Running   0               7m51s
kube-system   kube-proxy-jbtgs                            1/1     Running   0               71m
kube-system   kube-proxy-p62z8                            1/1     Running   0               18h
kube-system   kube-proxy-ztlqf                            1/1     Running   0               19h
kube-system   kube-scheduler-kube-master-node1            1/1     Running   3 (7m35s ago)   19h
kube-system   kube-scheduler-kube-master-node2            1/1     Running   0               7m50s
```

ìƒì„¸ ì¡°íšŒë¥¼ í•´ë³´ë‹ˆ ëª¨ë‘ Readiness probe ì‹¤íŒ¨ê°€ ë˜ì—ˆëŠ”ë° BGP í”¼ì–´ë§ì´ ì˜ ë˜ì§€ ì•Šì€ ê²ƒ ê°™ë‹¤.  
```bash
kubectl describe pod calico-node-n9p9r -n kube-system
##Print
Events:
  Type     Reason     Age                  From     Message
  ----     ------     ----                 ----     -------
  Warning  Unhealthy  16s (x466 over 68m)  kubelet  (combined from similar events): Readiness probe failed: 2022-07-19 02:38:55.795 [INFO][13044] confd/health.go 180: Number of node(s) with BGP peering established = 0
calico/node is not ready: BIRD is not ready: BGP not established with 10.20.1.232,10.20.1.67,10.20.2.10
```

ì•„ë˜ ì»¤ë§¨ë“œë¥¼ í†µí•´ ë°°í¬ëœ calico cnië¥¼ ì‚´í´ë³´ì.  
```bash
kubectl get pod calico-node-5kx97 -n kube-system -o yaml > calicocni.yml
```

`calicocni.yml`  
ë‹¤ìŒì€ ymlíŒŒì¼ ì¤‘ ì¼ë¶€ë¥¼ ë½‘ì€ ê²ƒì´ë‹¤. Calicoì˜ ê²½ìš° BIRD, FELIX ë¼ê³  í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ê°€ ì¡´ì¬í•œë‹¤.  
birdëŠ” BGP ë°ëª¬ì´ë©° Route Sharingì„ ìœ„í•œ í”„ë¡œì„¸ìŠ¤ì´ë‹¤. ì´ ë°ëª¬ì€ ë‹¤ë¥¸ ë…¸ë“œì— ìˆëŠ” BGPë°ëª¬ë“¤ê³¼ ë¼ìš°íŒ… ì •ë³´ë¥¼ êµí™˜í•œë‹¤.  
felixëŠ” etcdë¡œ ë¶€í„° ì •ë³´ë¥¼ ì½ì–´ ë¼ìš°íŒ… í…Œì´ë¸”ì„ ë§Œë“¤ê³  í˜¸ìŠ¤íŠ¸ì˜ ë¼ìš°íŠ¸ í…Œì´ë¸”ì„ ì„¤ì •í•œë‹¤.  
```yaml
image: docker.io/calico/node:v3.23.2
    imagePullPolicy: IfNotPresent
    lifecycle:
      preStop:
        exec:
          command:
          - /bin/calico-node
          - -shutdown
    livenessProbe:
      exec:
        command:
        - /bin/calico-node
        - -felix-live
        - -bird-live
      failureThreshold: 6
      initialDelaySeconds: 10
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 10
    name: calico-node
    readinessProbe:
      exec:
        command:
        - /bin/calico-node
        - -felix-ready
        - -bird-ready
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 10
```

í˜„ì¬ ë°œìƒë˜ê³  ìˆëŠ” ë¬¸ì œëŠ” í´ëŸ¬ìŠ¤í„° ë…¸ë“œê°„ birdë¼ê³  í•˜ëŠ” bgpë°ëª¬ì´ ê° ë…¸ë“œë“¤ ì‚¬ì´ì—ì„œ ë¼ìš°íŒ… ì •ë³´ë¥¼ ê³µìœ í•˜ëŠ” ë™ì•ˆ í†µì‹ ì´ ë¶ˆê°€í•˜ì—¬ ë°œìƒí•œ ë¬¸ì œë¡œ ë³´ì¸ë‹¤. 
ë”°ë¼ì„œ master, worker ë…¸ë“œê°„ BGP í¬íŠ¸ì¸ 179 í¬íŠ¸ë¥¼ ëª¨ë‘ í—ˆìš©í•´ ì¤€ë‹¤. 
ì´ í›„ì— íŒŒë“œì˜ ìƒíƒœë¥¼ ì‚´í´ë³´ë©´ ëª¨ë‘ ì •ìƒ ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.  
```bash
kubectl get pods -A
##Print 
NAMESPACE     NAME                                        READY   STATUS    RESTARTS        AGE
kube-system   calico-kube-controllers-6766647d54-gvsn6    1/1     Running   0               23h
kube-system   calico-node-5kx97                           1/1     Running   0               23h
kube-system   calico-node-h6qm4                           1/1     Running   0               22h
kube-system   calico-node-n9p9r                           1/1     Running   0               5h44m
kube-system   calico-node-sjmk7                           1/1     Running   0               4h40m
kube-system   coredns-6d4b75cb6d-bn4wg                    1/1     Running   0               23h
kube-system   coredns-6d4b75cb6d-rtl2f                    1/1     Running   0               23h
kube-system   etcd-kube-master-node1                      1/1     Running   2               23h
kube-system   etcd-kube-master-node2                      1/1     Running   0               4h40m
kube-system   kube-apiserver-kube-master-node1            1/1     Running   2               23h
kube-system   kube-apiserver-kube-master-node2            1/1     Running   0               4h40m
kube-system   kube-controller-manager-kube-master-node1   1/1     Running   3 (4h40m ago)   23h
kube-system   kube-controller-manager-kube-master-node2   1/1     Running   0               4h40m
kube-system   kube-proxy-dm4p8                            1/1     Running   0               4h40m
kube-system   kube-proxy-jbtgs                            1/1     Running   0               5h44m
kube-system   kube-proxy-p62z8                            1/1     Running   0               22h
kube-system   kube-proxy-ztlqf                            1/1     Running   0               23h
kube-system   kube-scheduler-kube-master-node1            1/1     Running   3 (4h40m ago)   23h
kube-system   kube-scheduler-kube-master-node2            1/1     Running   0               4h40m
```

ì¶”ê°€ì ìœ¼ë¡œëŠ” ì¡°ì¹˜ë¥¼ í•˜ê¸° ì´ì „ì— #1 ë²ˆì„ ë³´ë©´ master ë…¸ë“œì—ì„œ ë¼ìš°íŒ… ì •ë³´ë¥¼ ë´¤ì„ ë•Œ ìì‹ ì˜ ë…¸ë“œì˜ ìƒì„±ëœ podì˜ ë¼ìš°íŒ…ì •ë³´(cali interface)ë§Œ ì¡°íšŒê°€ ë˜ì—ˆë‹¤ê°€  
BGP í”„ë¡œí† ì½œì— ëŒ€í•œ í†µì‹ ì„ í—ˆìš©í•œ ì´ í›„ì—ëŠ” #2 ì™€ ê°™ì´ ë‹¤ë¥¸ ë…¸ë“œë“¤ì˜ íŒŒë“œë¡œ ë¼ìš°íŒ… ì •ë³´(tunl0 interface)ê°€ ì¶”ê°€ ëœ ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤.  
```bash
#1
netstat -nr
##Print 
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         10.20.1.1       0.0.0.0         UG        0 0          0 eth0
10.20.1.0       0.0.0.0         255.255.255.0   U         0 0          0 eth0
169.254.169.254 0.0.0.0         255.255.255.255 UH        0 0          0 eth0
192.168.57.128  0.0.0.0         255.255.255.192 U         0 0          0 *
192.168.57.129  0.0.0.0         255.255.255.255 UH        0 0          0 cali16b5fa8c7c3
192.168.57.130  0.0.0.0         255.255.255.255 UH        0 0          0 calicecbce59cab
192.168.57.131  0.0.0.0         255.255.255.255 UH        0 0          0 cali3193d48a378

#2
netstat -nr
##Print
Kernel IP routing table
Destination     Gateway         Genmask         Flags   MSS Window  irtt Iface
0.0.0.0         10.20.1.1       0.0.0.0         UG        0 0          0 eth0
10.20.1.0       0.0.0.0         255.255.255.0   U         0 0          0 eth0
169.254.169.254 0.0.0.0         255.255.255.255 UH        0 0          0 eth0
192.168.57.128  0.0.0.0         255.255.255.192 U         0 0          0 *
192.168.57.129  0.0.0.0         255.255.255.255 UH        0 0          0 cali16b5fa8c7c3
192.168.57.130  0.0.0.0         255.255.255.255 UH        0 0          0 calicecbce59cab
192.168.57.131  0.0.0.0         255.255.255.255 UH        0 0          0 cali3193d48a378
192.168.11.0    10.20.2.22      255.255.255.192 UG        0 0          0 tunl0
192.168.103.128 10.20.1.67      255.255.255.192 UG        0 0          0 tunl0
192.168.238.192 10.20.2.10      255.255.255.192 UG        0 0          0 tunl0
```

ì—¬ê¸°ì„œ CalicoëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ipipMode((IP in IP encapsulation)ë¥¼ ì‚¬ìš©í•˜ê³  ìˆìœ¼ë©° Direct, Vxlan ë°©ì‹ë„ ì¡´ì¬í•œë‹¤. 
ìì„¸í•œ ë‚´ìš©ì€ ë‹¤ë¥¸ í¬ìŠ¤íŒ…ì—ì„œ ë³„ë„ë¡œ ì‘ì„±í•´ ë³´ë„ë¡ í•œë‹¤.  
[Calico Encapsulation](https://projectcalico.docs.tigera.io/networking/vxlan-ipip)

<br>

### 2.2 kubeadm reset  
ë¬¸ì œê°€ ìƒê²¨ ì´ˆê¸°í™”ë¥¼ ì‹œì¼œì•¼ í•˜ëŠ” ê²½ìš° kubeadm resetì„ í†µí•´ ì´ˆê¸°í™”ê°€ ê°€ëŠ¥í•˜ë‹¤.  
ê° ë…¸ë“œì—ì„œ ì§„í–‰í•œë‹¤.  
```bash
kubeadm reset
##Print
The reset process does not clean CNI configuration. To do so, you must remove /etc/cni/net.d

The reset process does not reset or clean up iptables rules or IPVS tables.
If you wish to reset iptables, you must do so manually by using the "iptables" command.

If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar)
to reset your system's IPVS tables.

The reset process does not clean your kubeconfig files and you must remove them manually.
Please, check the contents of the $HOME/.kube/config file.
```
```bash
#Delete CNI Configuration
rm -rf /etc/cni/net.d

#init iptables
iptables -L
iptables -F
iptables -X

#check route table
route -n

route del -net 192.168.11.0    netmask 255.255.255.192 gw 10.20.2.22 
route del -net 192.168.57.128  netmask 255.255.255.192 gw 10.20.1.232
route del -net 192.168.103.128 netmask 255.255.255.192 gw 0.0.0.0    
route del -net 192.168.103.130 netmask 255.255.255.255 gw 0.0.0.0    
route del -net 192.168.103.133 netmask 255.255.255.255 gw 0.0.0.0    
route del -net 192.168.103.134 netmask 255.255.255.255 gw 0.0.0.0    
route del -net 192.168.238.192 netmask 255.255.255.192 gw 10.20.2.10 
```


---

## ğŸ“š References

[1] **kubeadm ì„¤ì¹˜í•˜ê¸°**  
- https://kubernetes.io/ko/docs/setup/production-environment/tools/kubeadm/install-kubeadm/

[2] **Creating a cluster with kubeadm**  
- https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/

[3] **Install Calico networking and network policy for on-premises deployments**  
- https://projectcalico.docs.tigera.io/getting-started/kubernetes/self-managed-onprem/onpremises

[4] **Calico Routing Modes**  
- https://www.youtube.com/watch?v=MpbIZ1SmEkU

[5] **ì°¸ê³ ë¬¸ì„œ**  
- https://lifeplan-b.tistory.com/155?category=886551

[6] **Containerd ì„¤ì¹˜ ë° ì„¤ì •**  
- https://trylhc.tistory.com/entry/Containerd-%EC%84%A4%EC%B9%98-%EB%B0%8F-%EC%84%A4%EC%A0%95

[7] **Overlay networking**  
- https://projectcalico.docs.tigera.io/networking/vxlan-ipip
