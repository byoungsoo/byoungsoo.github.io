---
layout: post
title: "Ollama on Local & EKS"
author: "Bys"
category: ml
date: 2025-12-04 01:00:00
keywords: "ollama, ai llm"
tags: ollama ai llm
---

n8n ì—ì„œ LLM ëª¨ë¸ì— APIë¥¼ í˜¸ì¶œí•´ì•¼ í…ŒìŠ¤íŠ¸ë¥¼ í•´ì•¼í•˜ëŠ”ë° OpenAI ì—ëŠ” ìµœì†Œ 5$ ê²°ì œë¥¼ í•´ì•¼í•˜ê³ (ì´ë¯¸ ê²°ì œë¥¼ í•´ì„œ ì‚¬ìš©ì€í•˜ì§€ë§Œ...), Gemini ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œëŠ” GCPì— Billing accountë¥¼ ë§Œë“¤ì–´ì„œ ê²°ì œì¹´ë“œë¥¼ ë“±ë¡í•˜ê³  ì‚¬ìš©(ì´ ë˜í•œ ì´ë¯¸ ì‚¬ìš©ì¤‘ì´ì§€ë§Œ...)í•´ì•¼ í•œë‹¤. 
ë¹„ìš©ì´ ë§ì´ ë‚˜ì˜¤ì§€ëŠ” ì•Šì§€ë§Œ í…ŒìŠ¤íŠ¸ ë‹¨ê³„ì—ì„œ LLM ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ë¥¼ í•˜ëŠ”ê²ƒë„ ì•„ë‹Œë° êµ³ì´ ë¹„ìš©ì„ ë‚´ë©´ì„œ ì‚¬ìš©í•´ì•¼í•  ì´ìœ ëŠ” ì—†ë‹¤ê³  ëŠê»´ì¡Œê³ , ë¡œì»¬ì—ì„œ LLM ëª¨ë¸ì„ ì‹¤í–‰í•˜ëŠ” ê²ƒìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ê¸°ë¡œ í–ˆë‹¤. ì´ì— ë”°ë¼ Ollama ë¥¼ ì´ìš©í•´ ë¡œì»¬ì—ì„œ LLM ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³  APIë¥¼ í…ŒìŠ¤íŠ¸ í•˜ëŠ” ê³¼ì •ì— ëŒ€í•´ ì§„í–‰í•´ë³´ê³ ì í•œë‹¤.
- ë‚˜ì˜ ê²½ìš° n8n ì„ EKSì— ì˜¬ë ¸ê¸° ë•Œë¬¸ì— ollama ë„ EKS ì—ì„œ êµ¬ë™í•˜ë ¤ê³  í•œë‹¤. 
- n8nì„ ë¡œì»¬ì—ì„œ ì„¤ì¹˜í–ˆë‹¤ë©´ ollama ë„ ë¡œì»¬ì—ì„œ ì„¤ì¹˜í•˜ë©´ ëœë‹¤.  

# [Ollama](https://ollama.com/)  
Ollama ëŠ” ë¡œì»¬ì—ì„œ ë‹¤ì–‘í•œ ì˜¤í”ˆì†ŒìŠ¤ LLMì„ ë‹¤ìš´ë¡œë“œí•˜ê³  ì‹¤í–‰í•  ìˆ˜ ìˆë„ë¡ í•œ ë„êµ¬ë‹¤.

## 1. [Install on Local](https://ollama.com/download)  

Ollama í˜ì´ì§€ì—ì„œ Ollama ë¥¼ ë‹¤ìš´ë¡œë“œ/ì„¤ì¹˜ í•˜ë©´ LLM ëª¨ë¸ì„ ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê³  ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. 

ë˜ëŠ”, Linux í™˜ê²½ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ Ollama ë¥¼ ì„¤ì¹˜í•  ìˆ˜ë„ ìˆë‹¤.  
```bash
curl -fsSL https://ollama.com/install.sh | sh
```


## 2. Ollama ë¥¼ í†µí•´ ëª¨ë¸ ì‹¤í–‰í•˜ê¸°  
Ollama ëŠ” Applicationìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ë„ ìˆê³ , `ollama serve` ì»¤ë§¨ë“œë¥¼ í†µí•´ ì‹¤í–‰í•  ìˆ˜ë„ ìˆë‹¤. ì–´ë–¤ ë°©ì‹ìœ¼ë¡œë“  Ollama ë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ í”„ë¡œì„¸ìŠ¤ê°€ ì¡íŒë‹¤.  

```bash
$ $ps -ef | grep ollama

504 24489 16659   0 10:42 ì˜¤ì „ ttys030    0:00.07 ollama serve
```

ì •ìƒ ë™ì‘ì¤‘ì´ë¼ë©´ 11434 í¬íŠ¸ì—ì„œ `Ollama is running` ì´ë¼ëŠ” ë©”ì„¸ì§€ë„ í™•ì¸ ê°€ëŠ¥í•˜ë‹¤.  
```bash
$ curl 'http://127.0.0.1:11434'

Ollama is running
```


## 3. Ollama ë¥¼ í†µí•´ ëª¨ë¸ ì‹¤í–‰í•˜ê¸° 
```bash
$ ollama --help
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  signin      Sign in to ollama.com
  signout     Sign out from ollama.com
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
```


Ollama ì—ì„œ ì‹¤í–‰ê°€ëŠ¥í•œ ëª¨ë¸ ì •ë³´ëŠ” [Ollama Github í˜ì´ì§€](https://github.com/ollama/ollama?tab=readme-ov-file#model-library)ì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë‹¤.  
ì‹¤í–‰í•˜ê³  ì‹¶ì€ ëª¨ë¸ì— ëŒ€í•´ì„œ ì•„ë˜ì™€ ê°™ì´ `ollama run` ì»¤ë§¨ë“œë¥¼ í†µí•´ ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆë‹¤. (ë¡œì»¬ì—ì„œ ì‹¤í–‰í•˜ê¸° ë•Œë¬¸ì— ê°€ê¸‰ì  ì‚¬ì´ì¦ˆê°€ ì‘ì€ ëª¨ë¸ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤.)
```bash
$ ollama run deepseek-r1

>>> Hi, I am korean. I am glad to chat with you.

Thinking...
Okay, the user is a Korean speaker who's happy to chat. That's a great start! They're being friendly and open, which makes the interaction feel warm and welcoming.
Since they didn't ask a specific question, I should keep the response light and encouraging. They might be just practicing English or casually chatting, so I'll match their energy with a cheerful tone.
I'll mention "Korean" twice to show I'm paying attention to their identity, and offer multiple options (English, Korean, or mixed) to let them guide the conversation. The emojis will help convey enthusiasm since text can feel flat without tone.
Hmm, they didn't specify their purpose, so I'll leave the door open with "anything at all" to encourage them to share if they want. The ğŸ˜Š feels appropriate hereâ€”it's friendly without being overbearing.
Wonder if they'll pick a topic or just keep it small-talk for now. Either way, staying adaptable is key.
...done thinking.

Hello! ğŸ˜Š It's great to hear that you're Koreanâ€”I'm so happy to chat with you! Do you want to practice English, talk about Korean culture, or just have a general conversation? Feel free to start with anything at all! ğŸ˜„

>>> Send a message (/? for help)
```
ì±„íŒ…ì„ ì‹œì‘í•˜ë©´ Thinking(ì‚¬ê³ )ê³¼ì •ì„ í†µí•´ ì‘ë‹µì„ ì£¼ëŠ”ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.  



## 3. [API ì‚¬ìš©í•˜ê¸°](https://github.com/ollama/ollama?tab=readme-ov-file#rest-api)

ì—”ë“œí¬ì¸íŠ¸ì— ëŒ€í•´ì„œ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ”ì§€ í™•ì¸í•´ë³´ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ APIë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆë‹¤. 
```bash
curl 'https://ollama.bys.asia/api/ps'

{"models":[{"name":"gpt-oss:latest","model":"gpt-oss:latest","size":14080309504,"digest":"17052f91a42e97930aa6e28a6c6c06a983e6a58dbb00434885a0cf5313e376f7","details":{"parent_model":"","format":"gguf","family":"gptoss","families":["gptoss"],"parameter_size":"20.9B","quantization_level":"MXFP4"},"expires_at":"2025-12-12T03:27:10.382897529Z","size_vram":0,"context_length":4096}]}
```

API ì‚¬ìš©ì˜ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ localhost ì£¼ì†Œë¥¼ í†µí•´ í˜¸ì¶œí•  ìˆ˜ ìˆìœ¼ë©° ì•„ë˜ì™€ ê°™ì´ ë‹µë³€ì´ ì˜¤ëŠ”ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.  

```bash
curl 'http://localhost:11434/api/chat' -d '{
  "model": "deepseek-r1",
  "messages": [
    { "role": "user", "content": "Hi, I am korean. I am glad to chat with you." }
  ]
}'

{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.43512Z","message":{"role":"assistant","content":"","thinking":"Okay"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.482729Z","message":{"role":"assistant","content":"","thinking":","},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.530557Z","message":{"role":"assistant","content":"","thinking":" the"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.579649Z","message":{"role":"assistant","content":"","thinking":" user"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.630073Z","message":{"role":"assistant","content":"","thinking":" is"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.677701Z","message":{"role":"assistant","content":"","thinking":" Korean"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:24.724552Z","message":{"role":"assistant","content":"","thinking":" and"},"done":false}
......
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:33.708162Z","message":{"role":"assistant","content":"","thinking":" positive"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:33.756876Z","message":{"role":"assistant","content":"","thinking":" seems"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:33.803082Z","message":{"role":"assistant","content":"","thinking":" right"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:33.850301Z","message":{"role":"assistant","content":"","thinking":".\n"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:33.989729Z","message":{"role":"assistant","content":"ì•ˆ"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.036608Z","message":{"role":"assistant","content":"ë…•"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.083558Z","message":{"role":"assistant","content":"í•˜ì„¸ìš”"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.130104Z","message":{"role":"assistant","content":"!"},"done":false}
......
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.422438Z","message":{"role":"assistant","content":"ì €"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.46951Z","message":{"role":"assistant","content":"ë„"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.517768Z","message":{"role":"assistant","content":" í•œêµ­"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.566924Z","message":{"role":"assistant","content":"ì–´"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.615945Z","message":{"role":"assistant","content":"ë¡œ"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.663252Z","message":{"role":"assistant","content":" ëŒ€"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:34.712532Z","message":{"role":"assistant","content":"í™”"},"done":false}
......
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.415095Z","message":{"role":"assistant","content":"ì—"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.462348Z","message":{"role":"assistant","content":" ëŒ€í•´"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.508886Z","message":{"role":"assistant","content":" ì´ì•¼ê¸°"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.55589Z","message":{"role":"assistant","content":"í•˜ê³ "},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.649849Z","message":{"role":"assistant","content":" ì‹¶"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.697227Z","message":{"role":"assistant","content":"ìœ¼"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.744548Z","message":{"role":"assistant","content":"ì‹ "},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.794448Z","message":{"role":"assistant","content":"ê°€"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.841586Z","message":{"role":"assistant","content":"ìš”"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.888454Z","message":{"role":"assistant","content":"?"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:35.981704Z","message":{"role":"assistant","content":" ğŸ˜Š"},"done":false}
{"model":"deepseek-r1","created_at":"2025-12-05T01:54:36.028287Z","message":{"role":"assistant","content":""},"done":true,"done_reason":"stop","total_duration":14212437792,"load_duration":164803125,"prompt_eval_count":17,"prompt_eval_duration":2354629375,"eval_count":245,"eval_duration":11576893495}
```

ì¶”í›„ LLMê³¼ ëŒ€í™”í•˜ëŠ” ì±„íŒ… ì„¸ì…˜ì„ ë§Œë“¤ ë•ŒëŠ” ì € ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µë“¤ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ íŒŒì‹±í•´ì„œ ì¡°ë¦½í•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•˜ë‹¤. message.content í•„ë“œ ê°’ì„ ì¶”ì¶œí•˜ì—¬ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ê³„ì† ì´ì–´ ë¶™ì´ê³ , "done": trueì¸ JSON ê°ì²´ê°€ ë‚˜íƒ€ë‚˜ë©´ ì‘ë‹µì´ ëë‚¬ìŒì„ ì¸ì§€í•˜ê³ , content í•„ë“œ ëª¨ìœ¼ê¸°ë¥¼ ì¤‘ë‹¨í•˜ëŠ” ê³¼ì •ìœ¼ë¡œ íŒŒì‹±í•´ì„œ ì¡°ë¦½í•˜ë©´ ëœë‹¤.  
ì´ ë•Œ LLMê³¼ ì—°ì†ì ì¸ ëŒ€í™”ë¥¼ í•˜ë ¤ë©´ ì´ì „ ëŒ€í™” ë‚´ìš©ì„ messages ë°°ì—´ì— ê³„ì† ì¶”ê°€í•˜ì—¬ ë‹¤ìŒ ìš”ì²­ ì‹œ í•¨ê»˜ ë³´ë‚´ì£¼ì–´ì•¼ LLMì´ ì´ì „ ëŒ€í™”ë¥¼ ê¸°ì–µí•˜ê³  ë¬¸ë§¥ì„ ìœ ì§€í•  ìˆ˜ ìˆë‹¤.  


ëª¨ë¸ì„ ì‹¤í–‰í•˜ê³  ì•„ë˜ íŒŒì´ì„  ì½”ë“œë¥¼ ìˆ˜í–‰í•˜ë©´ ì‹¤ì œ ë¡œì»¬ì—ì„œ Python ì½”ë“œë¥¼ í†µí•´ 
```python
import requests
import json
import sys
import threading
import time

# 'Thinking...' ë©”ì‹œì§€ë¥¼ ì œì–´í•˜ê¸° ìœ„í•œ ì „ì—­ ë³€ìˆ˜
stop_thinking_animation = threading.Event()
thinking_thread = None

def thinking_animation():
    """ë°±ê·¸ë¼ìš´ë“œì—ì„œ 'Thinking...' ì• ë‹ˆë©”ì´ì…˜ì„ ì¶œë ¥í•©ë‹ˆë‹¤."""
    base_message = "Thinking"
    dot_count = 0
    max_dots = 3 # ì ì˜ ìµœëŒ€ ê°œìˆ˜

    while not stop_thinking_animation.is_set():
        dots = "." * dot_count
        sys.stdout.write(f"\r{base_message}{dots}{' ' * (max_dots - dot_count)} ")
        sys.stdout.flush()
        
        dot_count = (dot_count + 1) % (max_dots + 1) # 0 -> 1 -> 2 -> 3 -> 0 ...
        time.sleep(0.5) # 0.5ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸

    sys.stdout.write(f"\r{' ' * (len(base_message) + max_dots + 1)}\r")
    sys.stdout.flush()


def chat_with_ollama(model_name: str, messages: list):
    """
    Ollama APIì™€ ì±„íŒ… ì„¸ì…˜ì„ ì§„í–‰í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ìŠ¤íŠ¸ë¦¬ë°ëœ í† í°ë§Œ ì¶œë ¥í•˜ê³ , ìµœì¢… ê²°ê³¼ëŠ” ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global thinking_thread

    url = "http://localhost:11434/api/chat"
    headers = {"Content-Type": "application/json"}
    
    payload = {
        "model": model_name,
        "messages": messages,
        "stream": True 
    }

    full_response_content = ""
    is_first_content_chunk = True # ì²« ë²ˆì§¸ content chunkì¸ì§€ í™•ì¸í•˜ëŠ” í”Œë˜ê·¸ (ì• ë‹ˆë©”ì´ì…˜ ì¤‘ì§€ ì‹œì  ê²°ì •)

    try:
        # LLM ì‘ë‹µì´ ì‹œì‘ë˜ê¸° ì „ì— 'Thinking...' ì• ë‹ˆë©”ì´ì…˜ì„ ì‹œì‘
        stop_thinking_animation.clear() # ì• ë‹ˆë©”ì´ì…˜ ì •ì§€ ì´ë²¤íŠ¸ ì´ˆê¸°í™”
        thinking_thread = threading.Thread(target=thinking_animation)
        thinking_thread.start()

        with requests.post(url, headers=headers, json=payload, stream=True) as response:
            response.raise_for_status() # HTTP ì—ëŸ¬ ë°œìƒ ì‹œ ì˜ˆì™¸ ì²˜ë¦¬

            for line in response.iter_lines():
                if line:
                    try:
                        json_data = json.loads(line)
                        
                        if json_data.get("done"):
                            break

                        content_chunk = json_data.get("message", {}).get("content", "")
                        
                        if content_chunk: # content_chunkê°€ ë¹„ì–´ìˆì§€ ì•Šë‹¤ë©´ (ì‹¤ì œ í† í°ì´ ë„ì°©í–ˆë‹¤ë©´)
                            if is_first_content_chunk:
                                # 'Thinking...' ì• ë‹ˆë©”ì´ì…˜ì„ ì •ì§€í•˜ê³  ì§€ì›€
                                stop_thinking_animation.set()
                                if thinking_thread and thinking_thread.is_alive(): # ìŠ¤ë ˆë“œê°€ ì‚´ì•„ìˆëŠ”ì§€ í™•ì¸
                                    thinking_thread.join() # ì• ë‹ˆë©”ì´ì…˜ ìŠ¤ë ˆë“œê°€ ì¢…ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°
                                # ê·¸ ìë¦¬ì— LLM í”„ë¡¬í”„íŠ¸ ì¶œë ¥
                                sys.stdout.write(f"{model_name}: ") # 'Thinking...'ì´ ì§€ì›Œì§„ ìë¦¬ì— ì¶œë ¥
                                sys.stdout.flush()
                                is_first_content_chunk = False 

                            full_response_content += content_chunk
                            # ëª¨ë¸ì´ ìƒì„±í•œ í† í°ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ í™”ë©´ì— ì¶œë ¥
                            sys.stdout.write(content_chunk)
                            sys.stdout.flush() 

                    except json.JSONDecodeError:
                        sys.stderr.write(f"Error decoding JSON: {line.decode('utf-8')}\n")
                        sys.stderr.flush()
                        continue

        # ëª¨ë“  ìŠ¤íŠ¸ë¦¬ë°ì´ ì™„ë£Œëœ í›„ ì• ë‹ˆë©”ì´ì…˜ì´ ì•„ì§ ì‹¤í–‰ ì¤‘ì´ë¼ë©´ ì •ì§€
        if thinking_thread and thinking_thread.is_alive():
            stop_thinking_animation.set()
            thinking_thread.join()
        
        return full_response_content

    except requests.exceptions.RequestException as e:
        sys.stderr.write(f"Error during API call: {e}\n")
        sys.stderr.flush()
        # ì—ëŸ¬ ë°œìƒ ì‹œ ì• ë‹ˆë©”ì´ì…˜ ê°•ì œ ì¢…ë£Œ
        if thinking_thread and thinking_thread.is_alive():
            stop_thinking_animation.set()
            thinking_thread.join()
        return f"An error occurred: {e}"

# --- ì±„íŒ… ì„¸ì…˜ ì˜ˆì‹œ ---
if __name__ == "__main__":
    conversation_history = []
    ollama_model = "deepseek-r1" # ì‚¬ìš©í•  Ollama ëª¨ë¸ ì´ë¦„

    print(f"Ollama ({ollama_model})ì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 'exit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")

    while True:
        user_input = input("You: ") # ìµœì´ˆ ì‚¬ìš©ì ì…ë ¥
        if user_input.lower() == 'exit':
            break
        
        conversation_history.append({"role": "user", "content": user_input})
        
        # ëª¨ë¸ì˜ ë‹µë³€ì„ ë°›ì•„ì„œ ì¶œë ¥í•©ë‹ˆë‹¤. chat_with_ollama í•¨ìˆ˜ ì•ˆì—ì„œ ì• ë‹ˆë©”ì´ì…˜ê³¼ í† í° ì¶œë ¥ì„ ë‹´ë‹¹.
        assistant_response_content = chat_with_ollama(ollama_model, conversation_history)
        
        # ëª¨ë¸ì˜ ì‘ë‹µì´ ëª¨ë‘ ì¶œë ¥ëœ í›„, ì¤„ë°”ê¿ˆ ì²˜ë¦¬
        sys.stdout.write("\n")
        sys.stdout.flush()

        # Ollama ì‘ë‹µì„ ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        if assistant_response_content:
            conversation_history.append({"role": "assistant", "content": assistant_response_content})

    print("ëŒ€í™”ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
```


ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì´ ì±—ì„ ì§„í–‰í•  ìˆ˜ ìˆë‹¤.  
```bash
(llm-chat) âœ  llm-chat git:(main) âœ— python llm_chat.py

Ollama (deepseek-r1)ì™€ ëŒ€í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. 'exit'ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.
You: Hi, I'm Korean.
Thinking..

deepseek-r1: Hi there! Welcome!
You: I want to learn english cahtting with you.
Thinking...

deepseek-r1: Great! Iâ€™d be happy to chat with you in English. ğŸ˜Š
We can talk about anythingâ€”like your day, interests, travel, movies, books, or even practice grammar and vocabulary.
Here are a few ways we can start:
1. Ask me a question, and Iâ€™ll answer in English.
2. You can tell me something about yourself.
3. We can have a simple conversation on a topic of your choice.
Which one would you like to do? Or just start with a simple question like:
ğŸ‘‰ Whatâ€™s one thing you enjoy doing in your free time?
Feel free to take your timeâ€”Iâ€™m here to help! ğŸ˜Š

You:
```


## 4. [Install on EKS](https://artifacthub.io/packages/helm/ollama-helm/ollama/1.35.0)  
EKSì—ëŠ” ollama helm ì°¨íŠ¸ë¥¼ í†µí•´ ì„¤ì¹˜í•  ìˆ˜ ìˆë‹¤.  
```bash
helm repo add otwld https://helm.otwld.com/
helm repo update
helm install ollama otwld/ollama --namespace ollama --create-namespace
```


ë‚˜ì˜ ê²½ìš°ì—ëŠ” ArgoCD ë¥¼ í†µí•´ ì§„í–‰í•˜ë¯€ë¡œ [ë‹¤ìŒ ì½”ë“œ](https://github.com/byoungsoo/argocd-values/tree/main/dev-ap2-eks-main/ollama)ë¥¼ í†µí•´ ë°°í¬í–ˆë‹¤.

`application.yaml`  
```yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: ollama
  namespace: argocd
spec:
  project: default
  sources:
    - repoURL: 'https://gitlab.bys.asia/bys/argocd-values.git'
      targetRevision: main
      ref: values
    - repoURL: https://helm.otwld.com/
      chart: ollama
      targetRevision: 1.35.0
      helm:
        releaseName: ollama
        valueFiles:
          - $values/dev-ap2-eks-main/ollama/values.yaml
  destination:
    server: https://kubernetes.default.svc
    namespace: ollama
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=false
```

`values.yaml`  
```yaml
ollama:
  port: 11434
  models:
    run:
      - gpt-oss:latest

ingress:
  enabled: true
  className: alb
  annotations:
    alb.ingress.kubernetes.io/group.name: eks-main-etc
    alb.ingress.kubernetes.io/subnets: bys-dev-sbn-az1-extelb,bys-dev-sbn-az2-extelb,bys-dev-sbn-az3-extelb,bys-dev-sbn-az4-extelb
    alb.ingress.kubernetes.io/scheme : internet-facing
    alb.ingress.kubernetes.io/security-groups: bys-dev-sg-alb-eks-main-etc
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS": 443}]'
    alb.ingress.kubernetes.io/ssl-policy: ELBSecurityPolicy-TLS13-1-2-2021-06
    alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-northeast-2:558846430793:certificate/3d2ce654-c747-4b3e-905b-17304b8962ef
    alb.ingress.kubernetes.io/healthcheck-path: /
    alb.ingress.kubernetes.io/healthcheck-interval-seconds: '15'
    alb.ingress.kubernetes.io/healthcheck-timeout-seconds: '10'
    alb.ingress.kubernetes.io/healthy-threshold-count: '2'
    alb.ingress.kubernetes.io/unhealthy-threshold-count: '4'
    alb.ingress.kubernetes.io/healthcheck-port: traffic-port
    alb.ingress.kubernetes.io/success-codes: 200,301,302
    alb.ingress.kubernetes.io/target-type: ip
    alb.ingress.kubernetes.io/tags: auto-delete=no
  hosts:
  - host: ollama.bys.asia
    paths:
      - path: /
        pathType: Prefix

resources:
  limits:
    cpu: 8000m
    memory: 24Gi
  requests:
    cpu: 4000m
    memory: 12Gi

persistentVolume:
  enabled: true
  size: 100Gi
  storageClass: ebs-sc-gp3
```

ë°°í¬ê°€ ì™„ë£Œë˜ê³  ë‚˜ë©´ ingressì— ì„¤ì •í•œ ollama.domain ì„ í†µí•´ ì ‘ê·¼ì„ í•  ìˆ˜ ìˆë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ python ì½”ë“œì—ì„œ localhost ì£¼ì†Œë§Œ ë³€ê²½í•´ì£¼ë©´ ëª¨ë¸ì„ ì§ì ‘ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ ëœë‹¤.  



## 5. Ollama on EKS í…ŒìŠ¤íŠ¸

API ê°€ ì •ìƒ í˜¸ì¶œ ë˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤.  
```bash
curl https://ollama.bys.asia/api/chat -d '{
  "model": "gpt-oss:latest",
  "messages": [
    { "role": "user", "content": "Hi, I am korean. I am glad to chat with you." }
  ]
}'

{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.09065486Z","message":{"role":"assistant","content":"","thinking":"We"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.171519147Z","message":{"role":"assistant","content":"","thinking":" need"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.261829246Z","message":{"role":"assistant","content":"","thinking":" to"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.403798455Z","message":{"role":"assistant","content":"","thinking":" respond"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.505952188Z","message":{"role":"assistant","content":"","thinking":" politely"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.664459811Z","message":{"role":"assistant","content":"","thinking":","},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:01.829044366Z","message":{"role":"assistant","content":"","thinking":" greet"},"done":false}
......
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:22.555279398Z","message":{"role":"assistant","content":" ê´€ì‹¬"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:22.720116314Z","message":{"role":"assistant","content":" ìˆëŠ”"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:22.807855494Z","message":{"role":"assistant","content":" ë¶„ì•¼"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:22.895112306Z","message":{"role":"assistant","content":"ê°€"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:22.981762119Z","message":{"role":"assistant","content":" ìˆ"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:23.072643267Z","message":{"role":"assistant","content":"ìœ¼ë©´"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:23.171914633Z","message":{"role":"assistant","content":" ì•Œë ¤"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:23.258159062Z","message":{"role":"assistant","content":"ì£¼ì„¸ìš”"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:23.344145949Z","message":{"role":"assistant","content":"!"},"done":false}
{"model":"gpt-oss:latest","created_at":"2025-12-12T03:27:23.430044746Z","message":{"role":"assistant","content":""},"done":true,"done_reason":"stop","total_duration":53007213377,"load_duration":479078041,"prompt_eval_count":81,"prompt_eval_duration":537760089,"eval_count":195,"eval_duration":22638001097}
```

íŒŒì´ì¬ ì½”ë“œì—ì„œë„ url ì£¼ì†Œë§Œ ë³€ê²½í•´ì£¼ë©´ ì´ì œ LLMê³¼ ëŒ€í™”ë¥¼ ì‹œì‘í•  ìˆ˜ ìˆë‹¤.  
```Python
def chat_with_ollama(model_name: str, messages: list):
    """
    Ollama APIì™€ ì±„íŒ… ì„¸ì…˜ì„ ì§„í–‰í•˜ê³  ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    ìŠ¤íŠ¸ë¦¬ë°ëœ í† í°ë§Œ ì¶œë ¥í•˜ê³ , ìµœì¢… ê²°ê³¼ëŠ” ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global thinking_thread

    url = "https://ollama.bys.asia/api/chat"
    headers = {"Content-Type": "application/json"}
    
    payload = {
        "model": model_name,
        "messages": messages,
        "stream": True 
    }
```


---

## ğŸ“š References

[1] **Ollama Helm**
- https://artifacthub.io/packages/helm/ollama-helm/ollama/1.35.0

[2] **Ollama API**
- https://github.com/ollama/ollama?tab=readme-ov-file#rest-api