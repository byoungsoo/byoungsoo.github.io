---
layout: post
title: "Tool Calling in LLMs - (LLM tool ì„ í™œìš©í•œ Chatbot êµ¬ì„±)"
author: "Bys"
category: ml
date: 2025-12-30 01:00:00
keywords: "tool, ai, llm"
tags: tool ai chatbot llm
---

# [Tools](https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html)  
- OpenAI: https://ai.google.dev/gemini-api/docs/function-calling?hl=ko&example=meeting
  > Function calling (also known as tool calling) provides a powerful and flexible way for OpenAI models to interface with external systems and access data outside their training data.

- Google: https://platform.openai.com/docs/guides/function-calling?api-mode=chat
  > Function calling lets you connect models to external tools and APIs.

- AWS: https://docs.aws.amazon.com/bedrock/latest/userguide/tool-use.html

OpenAI, Google ì˜ ë¬¸ì„œë¥¼ ì½ì–´ë³´ë©´ Function Calling(Tool calling)ì€  `ê²°êµ­ LLM ëª¨ë¸ë“¤ì´ ì™¸ë¶€ ì‹œìŠ¤í…œê³¼ ìƒí˜¸ì‘ìš©(Interface), ì—°ê²°(Connect) í•˜ê³  ì™¸ë¶€ ë°ì´í„°ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ë°©ë²•ì„ì„ ì•Œ ìˆ˜ ìˆë‹¤.`


## 1. [Tools ì´í•´í•˜ê¸°](https://platform.openai.com/docs/api-reference/chat/create#chat_create-tools)  
**ê°„ë‹¨íˆ í•µì‹¬ë§Œ ë³´ë©´ LLM ëª¨ë¸ì— APIë¥¼ í˜¸ì¶œí•  ë•Œ tools(function) ë¥¼ ì •ì˜í•˜ê³  ìš°ë¦¬ê°€ ì–´ë–¤ tools ê°€ì§€ê³  ìˆëŠ”ì§€ ì „ë‹¬ í•˜ëŠ” ê²ƒì´ í•µì‹¬ì´ë‹¤.** OpenAIì˜ Chat Completions API ë¥¼ ì‚´í´ë³´ë©´ Request Body ì— tools ë¥¼ ì „ë‹¬í•  ìˆ˜ ìˆë‹¤.

ì´ ì½”ë“œì—ì„œ tools ë¥¼ ì „ë‹¬í•˜ëŠ” ê²ƒì„ ë³¼ ìˆ˜ ìˆë‹¤. response = openai.chat.completions.create(model="gpt-oss:20b-cloud", messages=messages, `tools=tools`). ê·¸ë¦¬ê³  LLM ì€ tool í˜¸ì¶œì´ í•„ìš”í•˜ë‹¤ê³  íŒë‹¨ë˜ëŠ” ê²½ìš° `finish_reason` ì— `tool_calls` ë¥¼ ì „ë‹¬í•œë‹¤. 

ê·¸ëŸ¼ ì ë‹¹íˆ tool_calls ì¸ ê²½ìš° ì–´ë–¤ tool ì„ í˜¸ì¶œí•˜ë„ë¡ ì²˜ë¦¬í•´ì£¼ë©´ ë˜ëŠ”ë° ë°”ë¡œ ì•„ë˜ì˜ ì½”ë“œê°€ ê·¸ë ‡ë‹¤.  
```python
def chat(message, history):
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": message}]
    done = False
    while not done:

        # This is the call to the LLM - see that we pass in the tools json

        response = openai.chat.completions.create(model="gpt-oss:20b-cloud", messages=messages, tools=tools)
        finish_reason = response.choices[0].finish_reason
        print(f"response.choices: {response.choices}")
        # If the LLM wants to call a tool, we do that!
         
        if finish_reason=="tool_calls":
            message = response.choices[0].message
            print(f"message: {message}")
            tool_calls = message.tool_calls
            results = handle_tool_calls(tool_calls)
            messages.append(message)
            messages.extend(results)
        else:
            done = True
    return response.choices[0].message.content
```



tools ëŠ” ë¬¸ì„œ[3]ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ì„ ê°€ì§„ë‹¤. 
```json
{
  "tools": [
    {
      "type": "function",
      "function": {
        "name": "get_current_weather",
        "description": "íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "ë„ì‹œ ì´ë¦„ (ì˜ˆ: Seoul, Tokyo)"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"],
              "description": "ì˜¨ë„ ë‹¨ìœ„"
            }
          },
          "required": ["location"]
        }
      }
    },
    {
      "type": "function",
      "function": {
        "name": "record_current_weather",
        "description": "íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê¸°ë¡í•˜ê³  ì•ŒëŒì„ ë³´ë‚´ì¤ë‹ˆë‹¤.",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "ë„ì‹œ ì´ë¦„ (ì˜ˆ: Seoul, Tokyo)"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit"],
              "description": "ì˜¨ë„ ë‹¨ìœ„"
            }
          },
          "required": ["location"]
        }
      }
    }
  ]
}
``` 

<br><br>

## 2. ë‚ ì”¨ ì •ë³´ë¥¼ ë°›ì•„ì˜¤ëŠ” toolì„ êµ¬í˜„í•œ í…ŒìŠ¤íŠ¸

ë‹¤ìŒ ì½”ë“œë¥¼ ìœ„í•´ì„œ ì•„ë˜ì˜ ë‚´ìš©ì´ í•„ìš”í•˜ë‹¤.  
1. LLM - Ollama ë¡œì»¬ í™˜ê²½
2. Pushover API (ë¬´ë£Œ)
3. Openweather API (ë¬´ë£Œ)

ì•„ë˜ ì½”ë“œì—ì„œ tool(function)ì— í•´ë‹¹ í•˜ëŠ” ê±´ `get_current_weather, record_current_weather` í•¨ìˆ˜ë‹¤.  
LLMì— ì´ëŸ° toolì„ tools ë¡œ ì •ì˜í•˜ì—¬ ì „ë‹¬í•˜ë©°, system_prompt ì— ë§Œì•½ íŠ¹ì • ì§€ì—­ì˜ í˜„ì¬ ë‚ ì”¨ë¥¼ ëª¨ë¥¸ë‹¤ë©´ get_current_weather tool ì„ ì´ìš©í•˜ê³ , ì‚¬ìš©ìê°€ ì•ŒëŒì„ ë°›ê¸° ì›í•œë‹¤ë©´ record_current_weather í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ë¼ê³  ê°€ì´ë“œí•˜ê³  ìˆë‹¤.  

```python
# imports
from dotenv import load_dotenv
from openai import OpenAI
import json
import os
import requests
from pypdf import PdfReader
import gradio as gr
import random

# The usual start
load_dotenv(override=True)
openai = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"
)
model_name="gpt-oss:20b-cloud"


# For pushover (ì•ŒëŒì„ ë°›ê¸° ìœ„í•´)
# Pushover user found and starts with u
# Pushover token found and starts with a
pushover_user = os.getenv("PUSHOVER_USER")
pushover_token = os.getenv("PUSHOVER_TOKEN")
pushover_url = "https://api.pushover.net/1/messages.json"

if pushover_user:
    print(f"Pushover user found and starts with {pushover_user[0]}")
else:
    print("Pushover user not found")

if pushover_token:
    print(f"Pushover token found and starts with {pushover_token[0]}")
else:
    print("Pushover token not found")


def push(message):
    print(f"Push: {message}")
    payload = {"user": pushover_user, "token": pushover_token, "message": message}
    requests.post(pushover_url, data=payload)



def get_current_weather(location: str, unit: str = "celsius") -> str:
    """
    OpenWeatherMap APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
    
    Args:
        location: ë„ì‹œ ì´ë¦„ (ì˜ˆ: Seoul, Tokyo)
        unit: ì˜¨ë„ ë‹¨ìœ„ (celsius ë˜ëŠ” fahrenheit)
    
    Returns:
        JSON í˜•ì‹ì˜ ë‚ ì”¨ ì •ë³´ ë¬¸ìì—´
    """
    # OpenWeatherMap API í‚¤ (í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    api_key = os.getenv("OPENWEATHER_API_KEY")
    if not api_key:
        return json.dumps({"error": "OPENWEATHER_API_KEY not found"})
    
    # unit ê°’ ì •ê·œí™” (metric, celsius ëª¨ë‘ celsiusë¡œ ì²˜ë¦¬)
    if unit.lower() in ["metric", "celsius"]:
        unit = "celsius"
    elif unit.lower() in ["imperial", "fahrenheit"]:
        unit = "fahrenheit"
    
    # 1. Geocoding APIë¡œ ë„ì‹œ ì´ë¦„ì„ ìœ„ë„/ê²½ë„ë¡œ ë³€í™˜
    geo_url = f"http://api.openweathermap.org/geo/1.0/direct?q={location}&limit=1&appid={api_key}"
    
    try:
        geo_response = requests.get(geo_url, timeout=5)
        geo_response.raise_for_status()
        geo_data = geo_response.json()
        
        if not geo_data:
            return json.dumps({"error": f"ë„ì‹œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {location}"})
        
        lat = geo_data[0]['lat']
        lon = geo_data[0]['lon']
        
        # 2. Current Weather API í˜¸ì¶œ
        weather_url = f"https://api.openweathermap.org/data/2.5/weather?lat={lat}&lon={lon}&appid={api_key}&units=metric"
        weather_response = requests.get(weather_url, timeout=5)
        print(f"weather_response: {weather_response}")
        weather_response.raise_for_status()
        data = weather_response.json()
        
        # ì˜¨ë„ ë³€í™˜
        temp_c = data['main']['temp']
        temp_f = (temp_c * 9/5) + 32
        temperature = temp_c if unit == "celsius" else temp_f
        
        weather_data = {
            "location": data['name'],
            "temperature": round(temperature, 1),
            "unit": unit,
            "condition": data['weather'][0]['description'],
            "humidity": data['main']['humidity'],
            "wind_speed": data['wind']['speed']
        }
        return json.dumps(weather_data)
        
    except requests.exceptions.RequestException as e:
        return json.dumps({"error": f"API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"})


def record_current_weather(location: str, unit: str = "celsius"):
    weather_json = get_current_weather(location, unit)
    weather_data = json.loads(weather_json)
    if "error" in weather_data:
        push(f"Error: {weather_data['error']}")
        return {"recorded": "error", "message": weather_data['error']}
    
    push(f"Location: {weather_data['location']}\nTemperature: {weather_data['temperature']}Â°{weather_data['unit'][0].upper()}\nCondition: {weather_data['condition']}")
    return {"recorded": "ok"}



get_current_weather_json = {
    "name": "get_current_weather",
        "description": "íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤",
        "parameters": {
          "type": "object",
          "properties": {
            "location": {
              "type": "string",
              "description": "ë„ì‹œ ì´ë¦„ (ì˜ˆ: Seoul, Tokyo)"
            },
            "unit": {
              "type": "string",
              "enum": ["celsius", "fahrenheit", "metric", "imperial"],
              "description": "ì˜¨ë„ ë‹¨ìœ„ (celsius/metric ë˜ëŠ” fahrenheit/imperial)"
            }
          },
          "required": ["location"]
    }
}

record_current_weather_json = {
    "name": "record_current_weather",
    "description": "íŠ¹ì • ìœ„ì¹˜ì˜ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ê¸°ë¡í•˜ê³  ì•ŒëŒì„ ë³´ë‚´ì¤ë‹ˆë‹¤.",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "ë„ì‹œ ì´ë¦„ (ì˜ˆ: Seoul, Tokyo)"
        },
        "unit": {
          "type": "string",
          "enum": ["celsius", "fahrenheit"],
          "description": "ì˜¨ë„ ë‹¨ìœ„"
        }
      },
      "required": ["location"]
    }
}
    
tools = [{"type": "function", "function": get_current_weather_json},
        {"type": "function", "function": record_current_weather_json}]



def handle_tool_calls(tool_calls):
    results = []
    for tool_call in tool_calls:
        tool_name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)
        print(f"Tool called: {tool_name}", flush=True)
        tool = globals().get(tool_name)
        result = tool(**arguments) if tool else {}
        results.append({"role": "tool","content": json.dumps(result),"tool_call_id": tool_call.id})
    return results


# ì—¬ê¸°ì„œ ë„êµ¬ì˜ prompt ë¥¼ ì •ì˜í•´ì¤„ ìˆ˜ ìˆë‹¤.  
system_prompt = f"You are acting as weather caster \
If you don't know the weather in a specific city, you need to check the current weather in that city and answer. Since you don't know the current weather, you can check it using the get_current_weather tool.\
Also, if the user wants you to record the weather information and send an alert, you can use the record_current_weather tool to do so. When you decide to call record_current_weather function, then don't need to call get_current_weather tool.\
If the person is asking for the weather for a large area (for example, tell me the current weather in the United States), be sure to ask for the city again before calling the tool."

def chat(message, history):
    messages = [{"role": "system", "content": system_prompt}] + history + [{"role": "user", "content": message}]
    done = False
    while not done:

        # This is the call to the LLM - see that we pass in the tools json
        response = openai.chat.completions.create(model="gpt-oss:20b-cloud", messages=messages, tools=tools)
        finish_reason = response.choices[0].finish_reason
        print(f"response.choices: {response.choices}")
        
        # If the LLM wants to call a tool, we do that!
        if finish_reason=="tool_calls":
            message = response.choices[0].message
            print(f"message: {message}")
            tool_calls = message.tool_calls
            results = handle_tool_calls(tool_calls)
            messages.append(message)
            messages.extend(results)
        else:
            done = True
    return response.choices[0].message.content


gr.ChatInterface(chat, type="messages").launch()
```

<br><br>

## 3. í…ŒìŠ¤íŠ¸ ê²°ê³¼

ìœ„ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë©´ Gradio ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ LLM ëª¨ë¸ê³¼ ì±„íŒ…ì„ ì‹œì‘í•  ìˆ˜ ìˆê³  ì²« ë²ˆì§¸ ë‚ ì”¨ ìš”ì²­ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.  
### Test1
![test1.png](/assets/it/ml/tools/test1.png)  
ì„œìš¸ ë‚ ì”¨ë¥¼ ë¬¼ì–´ë³´ë‹ˆ get_current_weather í•¨ìˆ˜ë¥¼ í†µí•´ ë‚ ì”¨ë¥¼ ë°›ì•„ ì˜¨ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. response.choices ë¥¼ ì‚´í´ë³´ë©´ ì²« ë²ˆì§¸ ë‚ ì”¨ ìš”ì²­ì„ ë°›ìœ¼ë©´ `finish_reason` ì´ `tool_calls` ì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ ë•Œ handle_tool_calls ë¥¼ í†µí•´ í•¨ìˆ˜ê°€ í˜¸ì¶œëœê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤. 

### Test2
![test2.png](/assets/it/ml/tools/test2.png)  
ë¶€ì‚° ë‚ ì”¨ì— ëŒ€í•œ ì•ŒëŒì„ ìš”ì²­í•˜ë‹ˆ record_current_weather tool ì´ í˜¸ì¶œëœ ê²ƒì„ ì•Œ ìˆ˜ ìˆìœ¼ë©°, record_current_weather í•¨ìˆ˜ì˜ push í•¨ìˆ˜ í˜¸ì¶œì„ í†µí•´

![test3.png](/assets/it/ml/tools/test3.png){: width="50%" height="auto"}  
ì‹¤ì œ Pushover ì•±ì„ í†µí•´ í•¸ë“œí°ìœ¼ë¡œ ì•ŒëŒì„ ë°›ê²Œ ë  ìˆ˜ ìˆë‹¤.  

<br><br>

## 4. Tool í™œìš©ì˜ ì˜ë¯¸
ë‹¤ì‹œ ì²˜ìŒìœ¼ë¡œ ëŒì•„ì™€ì„œ. OpenAI ì™€ Google ì—ì„œëŠ” Tool calling(Function calling)ì— ëŒ€í•´ì„œ ì•„ë˜ì™€ ê°™ì´ ì •ì˜ í–ˆë‹¤.  
> Function calling (also known as tool calling) provides a powerful and flexible way for OpenAI models to interface with external systems and access data outside their training data.  
> Function calling lets you connect models to external tools and APIs.

ì¦‰, LLM ëª¨ë¸ ìì²´ê°€ í˜„ì¬ ë‚ ì”¨ë¥¼ ì•Œ ìˆ˜ëŠ” ì—†ì§€ë§Œ ì™¸ë¶€ ë„êµ¬(get_current_weather, record_current_weather)ë¥¼ í†µí•´ ì™¸ë¶€ ì‹œìŠ¤í…œ(openweathermap.org)ê³¼ ì¸í„°í˜ì´ìŠ¤ ë° ì—°ë™ë˜ì–´ ì‚¬ìš©ìì—ê²Œ í˜„ì¬ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤. ëª¨ë“  ì™¸ë¶€ì˜ í˜¸ì¶œ ê°€ëŠ¥í•œ API ëŠ” LLMê³¼ ì—°ë™ë˜ì–´ ì‚¬ìš©í•  ìˆ˜ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìœ¼ë©°, ë‹¤ì–‘í•œ tool ì„ ì •ì˜í•˜ê³  LLM ëª¨ë¸ê³¼ ì—°ë™í•¨ìœ¼ë¡œì„œ LLM ëª¨ë¸ì„ ë” ê°•ë ¥í•˜ê³  ìœ ì—°í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•  ìˆ˜ ìˆì—ˆë‹¤.  

---

## ğŸ“š References

[1] **OpenAI Function Calling**
- https://platform.openai.com/docs/guides/function-calling

[2] **Google Function Calling**
- https://platform.openai.com/docs/guides/function-calling?api-mode=chat

[3] **OpenAI Chat Completions API**
- https://platform.openai.com/docs/api-reference/chat/create

[4] **Udemy - AI Engineer Agentic Track**
- https://www.udemy.com/course/the-complete-agentic-ai-engineering-course