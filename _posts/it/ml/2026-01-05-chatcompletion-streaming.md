---
layout: post
title: "OpenAI API"
author: "Bys"
category: ml
date: 2026-01-05 01:00:00
keywords: "openai, agents, sdk"
tags: openai agents sdk
---

## Streaming vs Chat Completions API  

ì´ì „ì—ëŠ” Chat Completions API ë¥¼ í˜¸ì¶œí•´ ì±—ë´‡ì„ ë§Œë“¤ì—ˆëŠ”ë°, Agent ì¥ì—ì„œëŠ” Streamingì„ í†µí•´ ì‘ë‹µì„ ë°›ì•„ì™€ì„œ ì°¨ì´ì ì— ëŒ€í•´ì„œ ì‚´í´ë´¤ë‹¤.  


### 1. ì½”ë“œë¥¼ í†µí•œ ì˜ˆì‹œ  
[Chat Completions](https://platform.openai.com/docs/api-reference/chat)
> The Chat Completions API endpoint will generate a model response from a list of messages comprising a conversation.

```python
# Check the key - if you're not using OpenAI, check whichever key you're using! Ollama doesn't need a key.

import os
from openai import OpenAI

openai_api_key = os.getenv('OPENAI_API_KEY')
openai = OpenAI(
    base_url="http://localhost:11434/v1",
    api_key="ollama"
)

# And now - let's ask for a question:
question = "Please propose a hard, challenging question to assess someone's IQ. Respond only with the question."
messages = [{"role": "user", "content": question}]

response = openai.chat.completions.create(
    model="gpt-oss:20b-cloud",
    messages=messages
)

question = response.choices[0].message.content
print(question)

# form a new messages list
messages = [{"role": "user", "content": question}]
response = openai.chat.completions.create(
    model="gpt-oss:20b-cloud",
    messages=messages
)

answer = response.choices[0].message.content
print(answer)
```

[Streaming](https://openai.github.io/openai-agents-python/streaming/)
> Streaming lets you subscribe to updates of the agent run as it proceeds. This can be useful for showing the end-user progress updates and partial responses.

```python
# The imports
from dotenv import load_dotenv
from agents import Agent, Runner, trace

# The usual starting point
load_dotenv(override=True)


# Make an agent with name, instructions, model
agent = Agent(name="Jokestar", instructions="You are a jokestar, you tell jokes", model="gpt-3.5-turbo")

# Run the joke with Runner.run(agent, prompt) then print final_output
with trace("Telling a joke"):
    result = await Runner.run(agent, "Tell a joke about Autonomous AI Agents")
    print(result.final_output)
```

ë‘ ì½”ë“œ ëª¨ë‘ LLM ëª¨ë¸ì„ í˜¸ì¶œí•´ì„œ ì‘ë‹µì„ ë°›ì•„ì˜¨ë‹¤. í•˜ì§€ë§Œ, Chat Completion APIëŠ” response ì— ë™ê¸°ë°©ì‹ìœ¼ë¡œ ëª¨ë“  ë‹µë³€ì„ ë°›ì•„ì™€ì„œ ì²˜ë¦¬í•  ìˆ˜ ìˆê³ , Streaming ì€ ë¹„ë™ê¸°ì‹ìœ¼ë¡œ LLM ì—ì„œ ìƒì„±ë˜ëŠ” ë‹µë³€ ì¼ë¶€ ì¼ë¶€ë¥¼ ì¦‰ì‹œ ë°›ì•„ì™€ì„œ ë³´ì—¬ì¤€ë‹¤.  
í•˜ì§€ë§Œ, ë¬¸ì„œë¥¼ ìì„¸íˆ ì‚´í´ë³´ë‹ˆ Chat Completions API ì—ì„œë„ stream=True ì˜µì…˜ì„ í†µí•´ ìŠ¤íŠ¸ë¦¬ë°ì„ í•  ìˆ˜ ìˆì—ˆë‹¤.  

```python
stream = openai.chat.completions.create(
    model="gpt-oss:20b-cloud",
    messages=messages
    stream=True  # ì´ ë¶€ë¶„ì„ í†µí•´ ìŠ¤íŠ¸ë¦¼ìœ¼ë¡œ ê°€ëŠ¥
)
for chunk in stream:  # ë°˜ë³µë¬¸ í•„ìš”
    if chunk.choices[0].delta.content:  # ì¡°ê±´ í™•ì¸ í•„ìš”
        print(chunk.choices[0].delta.content)  # ì¡°ê° ì²˜ë¦¬
```

## 2. ë¬´ì—‡ì´ ë‹¤ë¥¸ê°€?
Chat Completions API ëŠ” openai ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ í˜¸ì¶œë˜ëŠ” ë¹„êµì  ë‹¨ìˆœí•œ API ì´ë©°, Streaming ì€ Agents SDK ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë¹„êµì  ë³µì¡í•œ ìˆ˜ì¤€ì˜ SDK/í”„ë ˆì„ì›Œí¬ë¡œ ì´í•´í•  ìˆ˜ ìˆë‹¤. 

| ê¸°ëŠ¥ | Chat Completions API | Agents SDK | ì„¤ëª… |
|------|---------------------|-----------|------|
| **ë©€í‹° ì—ì´ì „íŠ¸** | âŒ ì§ì ‘ êµ¬í˜„ í•„ìš” | âœ… ë‚´ì¥ ì§€ì› | ì—¬ëŸ¬ ì—ì´ì „íŠ¸ ê°„ í˜‘ì—… |
| **ë„êµ¬ í˜¸ì¶œ** | âš ï¸ ìˆ˜ë™ ì²˜ë¦¬ | âœ… ìë™ ì²˜ë¦¬ | í•¨ìˆ˜/API í˜¸ì¶œ ìë™í™” |
| **ëŒ€í™” ê´€ë¦¬** | âš ï¸ ìˆ˜ë™ ê´€ë¦¬ | âœ… ìë™ ê´€ë¦¬ | ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ê´€ë¦¬ |
| **íŠ¸ë ˆì´ì‹±** | âŒ ì—†ìŒ | âœ… `trace()` ì œê³µ | ë””ë²„ê¹… ë° ëª¨ë‹ˆí„°ë§ |
| **í•¸ë“œì˜¤í”„** | âŒ ì—†ìŒ | âœ… ì—ì´ì „íŠ¸ ê°„ ì „í™˜ ì§€ì› | ì‘ì—… ìœ„ì„ ê¸°ëŠ¥ |
| **ìŠ¤íŠ¸ë¦¬ë°** | âœ… `stream=True` | âœ… ìë™ ìŠ¤íŠ¸ë¦¬ë° | ì‹¤ì‹œê°„ ì‘ë‹µ |
| **ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜** | âŒ ì—†ìŒ | âœ… ë‚´ì¥ ì§€ì› | ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬ |
| **ë³µì¡ë„** | ğŸ”§ ë‚®ìŒ (ì§ì ‘ ì œì–´) | ğŸ¯ ë†’ìŒ (ì¶”ìƒí™”) | êµ¬í˜„ ë‚œì´ë„ |



## [3. Streaming ì‚¬ìš©ë²•](https://openai.github.io/openai-agents-python/streaming/)
Stream í•˜ê¸° ìœ„í•´ì„œëŠ” Runner.run_streamed() í˜¸ì¶œí•´ì„œ RunResultStreaming ê°ì²´ë¥¼ ë°›ì„ ìˆ˜ ìˆê³ , result.stream_events() ì—ì„œ ë¹„ë™ê¸°ì‹ìœ¼ë¡œ í˜¸ì¶œë˜ëŠ” ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ ì˜¤ë¸Œì íŠ¸ì˜ ìŠ¤íŠ¸ë¦¼ì„ ë°›ì„ ìˆ˜ ìˆë‹¤. 
```python
import asyncio
from openai.types.responses import ResponseTextDeltaEvent
from agents import Agent, Runner

async def main():
    agent = Agent(
        name="Joker",
        instructions="You are a helpful assistant.",
    )

    result = Runner.run_streamed(agent, input="Please tell me 5 jokes.")
    async for event in result.stream_events():
        if event.type == "raw_response_event" and isinstance(event.data, ResponseTextDeltaEvent):
            print(event.data.delta, end="", flush=True)


if __name__ == "__main__":
    asyncio.run(main())
```

ìœ„ ì½”ë“œì—ì„œ raw_response_event ì€ LLM ì—ì„œ ì§ì ‘ ì „ë‹¬ë˜ëŠ” raw ì´ë²¤íŠ¸ì´ë‹¤. ìœ„ ì½”ë“œì—ì„œëŠ” í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ ì½”ë“œë¡œ ì´í•´í•˜ë©´ ëœë‹¤.  


---

## ğŸ“š References

[1] **Chat Completions**
- https://platform.openai.com/docs/api-reference/chat

[2] **Streaming**
- https://openai.github.io/openai-agents-python/streaming/

[3] **Streaming events**
- https://openai.github.io/openai-agents-python/ref/stream_events/